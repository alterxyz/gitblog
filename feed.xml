<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/alterxyz/gitblog</id><title>RSS feed of alterxyz's gitblog</title><updated>2025-06-26T07:57:29.129947+00:00</updated><link href="https://github.com/alterxyz/gitblog"/><link href="https://raw.githubusercontent.com/alterxyz/gitblog/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><entry><id>https://github.com/alterxyz/gitblog/issues/7</id><title>关于指令遵循和上下文管理：解码 LLM 的“稀释”效应与企业级应用</title><updated>2025-06-26T07:57:29.404617+00:00</updated><content type="html"><![CDATA[<h1>稀释</h1>
<h2>超越“听话”：解码 LLM 的“稀释”效应与企业级应用</h2>
<p>大型语言模型（LLM）正以惊人的速度改变着我们与信息交互的方式。然而，当我们惊叹于 LLM 的强大能力时，是否曾深入思考过：LLM 真的完全“理解”并“遵循”了我们的指令吗？它们的输出，究竟是用户意图的忠实反映，还是模型自身“意志”的某种体现？“幻觉”又是如何产生的？</p>
<p>本文将围绕 LLM 的“指令遵循”展开深入探讨，揭示其多维度特性，并引入“稀释效应”的概念来解释 LLM 在处理复杂信息时的行为模式。我们将重点关注“稀释效应”如何影响 LLM 的企业级应用，并探讨如何通过工程化手段，实现更精准的控制和更可靠的结果，以及最终实现人机协同。</p>
<p>一、 指令的多维性：不只是用户的 Prompt</p>
<p>当我们向 LLM 发出一个指令（Prompt）时，我们通常期望它能准确理解我们的意图。但实际上，LLM 的行为并非仅仅由我们的 Prompt 决定。除了用户明确输入的指令外，LLM 还会受到至少以下两个方面的影响：</p>
<ol>
<li>模型提供商的预设：LLM 的训练数据、预设规则、以及模型提供商为确保模型安全、合规、高效而制定的各种“最佳实践”，都会潜移默化地影响 LLM 的输出。</li>
<li>模型的推理过程：特别是对于专门的推理模型（如 DeepSeek），它们在处理问题时会大量借鉴自身的预训练知识和推理策略，这可能导致最终输出偏离用户最初的意图。</li>
</ol>
<p>这种多维度“指令”的交织，使得 LLM 的行为变得复杂。理解这种复杂性，是构建可靠的企业级 LLM 应用的前提。</p>
<p>二、 “稀释效应”：理解 LLM 的“思考”过程</p>
<p>为了更好地理解 LLM 在处理多维度“指令”时的行为模式，我们可以引入“稀释效应”的概念。所谓“稀释”，是指在 LLM 的推理过程中，用户输入的原始指令，会被模型自身的预训练知识、推理策略以及模型提供商的预设等因素所“稀释”，导致最终输出偏离用户最初的预期。</p>
<p>我们可以将不同来源的信息类比为不同密度的物质：</p>
<ul>
<li>用户 Prompt: 密度最高，代表用户的核心意图，如同恒星，是系统的核心。</li>
<li>RAG 知识库: 密度中等，提供额外的上下文信息，如同行星，围绕恒星运转，提供补充信息。</li>
<li>模型自身的推理: 密度也较高, 且体量较大，如同星云，在系统中弥漫，影响着整个系统的状态。</li>
</ul>
<p>当这些不同“密度”的信息在 LLM 内部相互作用时，就可能出现“稀释效应”。用户的原始指令（恒星）可能被模型自身的推理（星云）所“遮蔽”或“扭曲”，导致最终输出的结果并非完全符合用户预期。</p>
<p>“稀释”的演进：从“人工稀释 1.0”到“模型稀释 1.0”</p>
<p>“稀释”效应并非一开始就存在。随着 LLM 技术的发展，“稀释”的形式也在不断演进：</p>
<ul>
<li>
<p>人工稀释 1.0（RAG）: RAG（Retrieval-Augmented Generation）技术可以被视为一种“人工稀释”。通过 RAG，我们将用户的 Prompt 与外部知识库的信息融合，人为地增加了模型的输入信息量，从而“稀释”了原始 Prompt 的直接影响。这种“稀释”是人为可控的，我们可以选择知识库、调整检索策略来控制“稀释”的程度和方向。</p>
</li>
<li>
<p>模型稀释 1.0（Thinking 模型）: Thinking 模型则代表了一种“模型自身驱动的稀释”。这类模型在推理过程中会产生大量的中间步骤和思考过程，这些“思考”虽然提升了模型的整体性能，但也进一步“稀释”了用户原始指令的权重。这种“稀释”是模型自身能力提升的体现，但也更难以直接控制。</p>
</li>
</ul>
<p>三、 “幻觉”的本质： “稀释”与“对齐”的失衡</p>
<p>长期以来，LLM 的“幻觉”（Hallucination）问题一直困扰着业界。但如果我们从“稀释效应”的角度来看待“幻觉”，或许可以得到更深刻的理解。</p>
<p>“幻觉”并非 LLM 凭空捏造了不存在的事实，而是模型在多维度“指令”和自身推理的复杂作用下，产生的与人类认知或期望不符的输出。这更像是一种“对齐”问题，而非简单的“错误”。</p>
<p>“幻觉”往往源于：</p>
<ul>
<li>潜台词和暗上下文: 用户 Prompt 中未明确表达的意图、隐含的假设、以及相关的背景知识，都可能成为模型“脑补”的素材，这可以视为一种“隐性稀释”。</li>
<li>过强的指令遵循: 当模型过分“听话”，试图从有限的输入中推断出过多信息时，也容易产生“幻觉”。</li>
<li>“稀释”过度: 当模型自身的推理和预训练知识过度主导输出结果时，“幻觉”就更容易出现。</li>
</ul>
<p>与其将“幻觉”视为“错误”并试图“纠正”，不如将其视为“稀释”的极端表现，通过工程化手段来 “引导和参与”“稀释” 的过程，实现模型输出与人类期望的“对齐”。</p>
<p>四、 企业级应用：驾驭“稀释”，实现人机协同</p>
<p>对于企业级 LLM 应用而言，理解和驾驭“稀释效应”至关重要。企业既希望 LLM 能够充分利用其强大的推理能力，产生更智能、更深入的洞察，又希望 LLM 的输出能够符合企业的特定需求、风格和规范。</p>
<p>这就需要我们 <strong>不仅仅是“控制”稀释，更是“引导”和“参与”稀释</strong>：</p>
<ul>
<li>Prompt 工程: 通过精心设计的 Prompt，明确用户意图，引导模型进行“有方向的稀释”。</li>
<li>RAG: 利用 RAG 技术，引入与企业相关的知识库，进行“可控的稀释”，为模型提供更精准的上下文。</li>
<li>Workflow 编排: 通过 Workflow 工具，将复杂的任务分解为多个步骤，并在每个步骤中对“稀释”进行精细化控制。</li>
<li>模型微调: 针对特定任务或领域，对模型进行微调，使其“稀释”的方向更符合企业需求。</li>
</ul>
<p>作为 LLM 平台提供商，我们致力于为企业提供构建、管理和优化 LLM 应用的工具和环境。我们的平台提供：</p>
<ul>
<li>灵活的 Prompt 工程工具: 帮助企业构建更精准、更有效的 Prompt，更好地引导 LLM 的行为。</li>
<li>强大的 RAG 集成能力: 允许企业将 LLM 与内部知识库无缝对接，为 LLM 提供更丰富、更可靠的上下文信息，实现“可控稀释”。</li>
<li>多样化的 Workflow 编排选项: 支持企业根据不同的业务场景，灵活定制 LLM 的工作流程，实现对“稀释”过程的精细化控制和引导。</li>
<li>深度定制和优化服务: 为有特殊需求的企业提供专业的咨询和技术支持，帮助企业构建高度定制化的 LLM 应用。</li>
</ul>
<p>我们相信，通过这些工具和服务，企业可以更好地驾驭 LLM，充分利用“稀释效应”的正面作用，实现 LLM 与人类的深度协同，共同创造更大的价值。</p>
<p>五、 总结与展望</p>
<p>LLM 的“指令遵循”并非简单的“是”或“否”的问题，而是一个涉及多维度“指令”交互、以及“稀释效应”影响的复杂过程。理解“稀释”，驾驭“稀释”，是释放 LLM 潜力的关键。</p>
<p>“稀释”并非 LLM 的缺陷，而是其强大推理能力的体现。关键在于如何通过工程化手段，让人类更好地“参与”到“稀释”过程中，实现 LLM 输出与人类期望的“对齐”，最终实现人机协同。</p>
<p>(由 Gemini 2.0 Pro, Flash-Thinking, Claude 3 Opus, 我 共同完成)</p>
<hr />
<h2>初稿</h2>
<p>模型的 “指令遵循” 和 结果效果是个很有意思的话题。</p>
<p>举例更好说明一些：</p>
<p>Claude.ai 和 ChatGPT.com 听用户 七到九分（满分 10），听 Anthropic/OpenAI 的 五到八分。</p>
<p>那么就会出现情况：7 分听用户的， 但是 8 分听了 OpenAI 的 - Prompt 和 工具 和里面（训练时）提供的各种 best practice（Eg. 今天起，ChatGPT 搜索人人可用，OpenAI 疯狂砸钱，雇 300+博士为 AI 打工-36 氪) 。</p>
<p>中学生问的题，博士可不一定按他想象地给答案和过程。</p>
<p>而另一个指令遵循是 9 分听用户，五六分听自己的，那么模型就很容易被 jailbreak。</p>
<p>我理解的 DeepSeek 和其他 推理模型的一个核心在于，后者（prompt/训练集/best practice/后训练）的内容无所谓，有高有低。
但前面 “听用户的” 部分，比如还是 9 分，但是推理部分也在 prompt 里，它稀释了原始用户。那么构成就是：</p>
<p>用户 9 + 模型和供应商本身的意愿 5 ➡️ 纯用户 6 + （推理部分 3 + model 5）。</p>
<p>那么稀释后的用户端指令遵循就只有 42%，低于 50%
（顺便，小模型可能总分低于 5 啥的。）
这就导致了推理模型的上下限都比大模型更大。</p>
<p>开发者是另一个情况。各路 playground 比如 Google ai studio 普遍允许修改 prompt 说过的话。注意力架构是高度依赖上下文的，那么这样就是 hack 了 “模型和供应商本身的意愿” 这部分，通过修改上下文 - 模型相信自己（but hacked）。</p>
<p>Prompt 是更温和的修改，hack 过于激进且难以复现和投产。（但或许有办法解决？）</p>
<p>模型商在预训练或者微调时提供 best practice，而企业用户通常通过 prompt - rag 技术等。</p>
<p>那么，或许模型等指令遵从能力，有表现形态，以及遵循谁的问题。</p>
<p>Deep Research 听 OpenAI 搭建的高质量素材，以及 prompt 进去的高质量论文，其次才是用户（某种角度上说）（我在自己的笔记有记录另一个思考，简单来说是事件的实现是三部分：意识意义愿景-&gt;意愿意志决策-&gt;推理计算运行）。
那么，我认为企业肯定也会需要 Deep Research，但是 prompt 进去的可能是内部文件和风格品牌。
模型既吃企业画的饼（意识层），也吃成员投入的燃料（意愿层）。</p>
<p>推理模型的一个特点是稀释。
另一个角度解读是，理想状态下，它仍然遵循人的 query - 在愿景 意识层；
至于决策 也就是意愿层，它会听自己的而不完全是用户给的，并 best practice 可能比一般人做得更好。</p>
<p>那么指令遵循当然还是遵循，只是用户画的饼它听，博士和全人类给的参考答案 推理过程 和计算器 numpy 的结果 它也听。</p>
<p>遵守 - 带来可用性，以及推理模型 - 带来能力的增强。</p>
<p>这是一个敲敲打打的工程学，可能并非科学甚至原理数学层面的突破。
当然，有一个过硬的基座模型是必要的。Anthropic 也这样说过，预训练是可通关的，很多厂商也阶段性地做到了。</p>
<p>推理模型类似全自动 agent，目前高度不可控。
接下来的话，prompt 够用吗？或者提供 rag 够用吗？workflow 够用吗？需不需要，以及如何介入推理环节？
企业的需求是什么，会为什么买账（在后 reasoning 和 后 agent 时代）？</p>
<hr />
<p>高质量愿景是稀缺的，高质量决策可以由 贵的好的 llm providers 提供。
那么一般员工做的，无非就是 搬运愿景，偶尔修改 - 添加随机性，将愿景（意识层）翻译为决策（意愿层）和行动。
超级个体在 LLM 带来的新时代，个体们会如何实现那三层？或者说超级个体的定义是什么，祂会什么样的形态存在？</p>
<h2>预告</h2>
<p>meta-dynamic 关于“三层”</p>
<h2>metadata</h2>
<blockquote>
<p>author: alterxyz (jerome @ dify.ai)
date: 2025年2月6日 初稿；2025年2月10日 正文</p>
</blockquote>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/7"/><published>2025-06-26T07:57:14+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/6</id><title>关于 memory 的重要性</title><updated>2025-06-26T07:57:29.554939+00:00</updated><content type="html"><![CDATA[<p>一个稳定可靠，或者至少自洽的记忆是至关重要的。如此才能构建一个自然的人格。
无论是人还是 AI。</p>
<p>很同意这会是个全面的工程。prompt engineering 之前很多人只是狭义的讨论 提示词么？那么重命名为 context engineering 也算是一种 refreshing 了挺好的。就像 agent 有点被炒作炒烂了，于是 agentic 这个词就又悄然成了共识。</p>
<details>
  <summary>塑造 AI 思维：从提示到上下文工程的战略转移 (Gemini Deep Research)</summary>
<h1><strong>塑造 AI 思维：从提示到上下文工程的战略转移</strong></h1>
<p><strong>执行摘要</strong></p>
<p>本报告旨在深入剖析人工智能应用开发领域的一项根本性转变：从“提示工程”（Prompt Engineering）到“上下文工程”（Context Engineering）的演进。这一转变并非简单的术语更迭，而是标志着行业从关注局部文本优化的“技艺”阶段，迈向了构建整体信息生态系统的“工程”纪元。Andrej Karpathy 等行业思想领袖的论述，为这一业已存在的实践赋予了明确的名称，从而加速了其理论化和体系化进程。</p>
<p>上下文工程的核心在于，它不再局限于雕琢单个输入指令，而是致力于设计和构建一个完整的、动态的信息环境。这个环境囊括了数据管道、检索机制、交互历史、可用工具以及领域知识，其最终目的是为了赋能大型语言模型（LLM）以一种可靠、可扩展且可预测的方式，完成复杂的、多步骤的真实世界任务。</p>
<p>本报告将系统性地阐述此范式转移。首先，我们将明确界定提示工程与上下文工程的范畴与区别，确立后者作为一种更宏大、更具系统性的工程学科的地位。其次，我们将深入技术层面，详细解析支撑上下文工程的核心架构，特别是以“检索增强生成”（Retrieval-Augmented Generation, RAG）为代表的技术栈及其高级实现。随后，报告将通过分析 DoorDash、LinkedIn 及 Perplexity AI 等前沿企业的真实案例，展示上下文工程在商业实践中的具体应用与巨大价值。最后，我们将探讨这一转变对 AI 开发者角色、技能需求及企业数据战略的深远影响，并为技术从业者与领导者提供前瞻性的战略展望与行动建议。</p>
<hr />
<h2><strong>第一部分：语义的演进：从雕琢词句到构建世界</strong></h2>
<p>人工智能应用开发领域正经历一场深刻的认知升级，其核心在于我们将如何与大型语言模型（LLM）协作。这场变革的焦点，正从如何“提问”的技艺，转向如何为其构建一个完整“世界观”的工程学科。著名 AI 科学家 Andrej Karpathy 的观点成为了这场讨论的催化剂，他主张使用“上下文工程”这一术语，因为它更精确地捕捉了当前 AI 开发的核心挑战，标志着该领域向着更成熟、更体系化的方向发展。</p>
<h3><strong>1.1 Karpathy 的催化作用：为新前沿命名</strong></h3>
<p>当 Andrej Karpathy 提出应更多地讨论“上下文工程”而非“提示工程”时，他并非发明了一个全新的概念，而是为一种已在顶尖开发者实践中普遍存在的趋势进行了精准命名 1。这一举动意义重大，因为它正式宣告了 AI 开发正在走出“凭感觉编程”（vibe coding）的早期探索阶段——一个开发者们更多是在实验和感受 AI 工具能力的时期 3。</p>
<p>开发者社区的积极反响证实了这一命名的时效性。许多工程师表示，他们早已在实践中朝着这个方向努力，但一直缺少一个恰当的词汇来概括这种系统性的工作 1。Karpathy 的提法，恰如其分地将零散的实践经验凝聚成一个清晰的学科方向，推动了行业共识的形成。它强调，决定高级 AI 应用成败的关键，已不再是那灵光一现的“神奇提示词”，而是其背后那个精心构建、持续供给信息的系统。</p>
<h3><strong>1.2 概念界定：范围与维度的差异</strong></h3>
<p>为了“正本清源”，必须精确地区分提示工程与上下文工程。二者的根本差异在于其工作范围、目标和所处的抽象层次。</p>
<ul>
<li><strong>提示工程（Prompt Engineering）</strong>：可以被狭义地定义为一种<strong>技艺</strong>，其核心目标是<strong>优化文本输入</strong>。它专注于通过精心选择和组织词语、短语、句子结构乃至标点符号，来引导 LLM 在<strong>单次或有限次的交互</strong>中生成最符合预期的、高质量的输出 6。其本质是追求与模型进行清晰、高效的沟通，好比一位管理者向员工下达明确无误的工作指令 9。它的作用域是用户与模型之间的那个“提示词”本身。  </li>
<li><strong>上下文工程（Context Engineering）</strong>：则是一门<strong>工程学科</strong>，其核心目标是<strong>设计和构建动态的、可扩展的系统</strong>。这个系统负责为 LLM 提供完成复杂任务所需的一切元素：正确的信息、可用的工具、相关的历史对话、明确的指令以及领域知识，并确保这些元素以正确的格式被动态地组织和利用 9。它关注的不是单次交互，而是整个<br />
<strong>信息生态系统</strong>的构建与维护，这个生态系统将支撑 AI 在连续的、多步骤的流程中可靠地运行 6。</li>
</ul>
<p>由此可见，<strong>提示工程是上下文工程的一个子集</strong> 9。这个观点至关重要。如果将构建一个 AI 应用比作烹饪，那么提示工程就像是撰写一份清晰的菜谱（recipe），而上下文工程则是设计整座厨房（kitchen）：包括决定食材的采购渠道与标准（数据源与质量）、设计食材处理流水线（数据管道）、配置厨具（工具集），并教会厨师（LLM）如何理解菜谱、使用厨具以及记住顾客的口味偏好（交互历史与个性化）12。</p>
<h3><strong>1.3 为何需要这种转变：从局部优化到系统可靠性</strong></h3>
<p>在真实的生产环境中，单纯依赖提示工程的局限性显而易见。一个措辞再完美的提示，也无法弥补上下文信息的缺失或错误 14。开发者们发现，为了让 AI 应用在面对各种边缘情况时依然能保持稳定和一致，他们花费在准备和构建上下文上的时间，远超调整提示词本身 14。</p>
<p>这种转变的根本原因在于，它触及了 LLM 应用失败的核心症结。大多数情况下，模型表现不佳并非源于其“智力”不足，而是因为它没有获得做出正确判断所必需的信息 11。上下文工程将开发的重心从优化那个最终提交给模型的、静态的“提示字符串”，转移到了动态地管理和填充整个“上下文窗口”（Context Window）——这个模型在进行推理时能够看到的所有信息的总和。</p>
<p>这种从“技艺”到“工程”的语义演进，其背后是行业专业化和成熟化的必然趋势。将这一核心工作冠以“工程”之名，本身就是一种战略性的举措。它摒弃了“提示工程”一词常带有的、类似“炼金术”或“黑客技巧”的临时性和不可捉摸感 10，而引入了系统化、可重复、可度量、可维护的工程学内涵 14。这使得 AI 应用的开发过程能够与成熟的软件开发生命周期（SDLC）和 DevOps 理念相结合 15，从而更容易被企业级应用所接纳和投资。企业愿意为有明确投资回报率的工程学科投入资源，而非模糊的“手艺”。因此，将“上下文”提升到工程的高度，是推动生成式 AI 从有趣的玩具转变为可靠的生产力工具的关键一步。</p>
<p><strong>表 1：提示工程 vs. 上下文工程：核心差异对比</strong></p>
<table>
<thead>
<tr>
<th align="left">特征</th>
<th align="left">提示工程 (Prompt Engineering)</th>
<th align="left">上下文工程 (Context Engineering)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>核心目标</strong></td>
<td align="left">引导模型生成特定的、高质量的单次响应。</td>
<td align="left">构建一个能支持模型持续、可靠执行复杂任务的系统。</td>
</tr>
<tr>
<td align="left"><strong>工作范畴</strong></td>
<td align="left">用户输入的指令字符串（Prompt）。</td>
<td align="left">整个信息环境，包括数据、工具、历史记录、外部知识库等。</td>
</tr>
<tr>
<td align="left"><strong>核心隐喻</strong></td>
<td align="left">撰写一份清晰明确的菜谱。</td>
<td align="left">设计、建造并运营整座自动化厨房。</td>
</tr>
<tr>
<td align="left"><strong>关键技能</strong></td>
<td align="left">语言表达、创意构思、指令清晰度、领域知识的文字化。</td>
<td align="left">系统设计、数据架构、信息检索、API 集成、流程编排。</td>
</tr>
<tr>
<td align="left"><strong>时间维度</strong></td>
<td align="left">关注单次交互或孤立的任务。</td>
<td align="left">关注连续的、多轮的、可能长期运行的交互流程。</td>
</tr>
<tr>
<td align="left"><strong>产出物</strong></td>
<td align="left">一个或一组精心设计的文本提示模板。</td>
<td align="left">一套完整的数据管道、检索系统、Agentic 框架或评估体系。</td>
</tr>
<tr>
<td align="left"><strong>关注点</strong></td>
<td align="left">“我应该<strong>如何问</strong>这个问题？”</td>
<td align="left">“为了让 AI 能回答这类问题，它需要<strong>知道什么</strong>？”</td>
</tr>
</tbody></table><hr />
<h2><strong>第二部分：上下文工程的架构基石</strong></h2>
<p>如果说上下文工程是构建智能应用的蓝图，那么其实现则依赖于一套坚实的、以数据为中心的架构。这一架构的核心思想是，不再仅仅依赖 LLM 内部固化的、可能过时的知识，而是通过动态地、实时地为其注入外部世界的信息来增强其能力。本节将深入剖析支撑上下文工程的技术体系，从核心引擎 RAG 到更为复杂的生产级实现。</p>
<h3><strong>2.1 检索增强生成 (RAG)：核心驱动引擎</strong></h3>
<p>检索增强生成（Retrieval-Augmented Generation, RAG）是上下文工程中最核心、最广为人知的技术框架 17。它通过将传统的信息检索系统（如搜索引擎和数据库）与 LLM 的强大生成能力相结合，从根本上解决了 LLM 的一些固有缺陷。</p>
<ul>
<li><strong>定义与目的</strong>：RAG 的核心目的在于，通过从外部权威知识库中检索相关信息，来“增强”LLM 的生成过程，从而使其回答更加准确、及时，并有事实依据 18。这极大地缓解了 LLM 的“幻觉”（Hallucination）问题，即模型在缺乏知识时凭空捏造事实的倾向 9。对于企业而言，RAG 的最大价值在于，它允许组织利用自己最新的、专有的内部数据来驱动 AI 应用，而无需承担重新训练或微调大型模型所带来的高昂计算和财务成本 19。  </li>
<li>
<strong>RAG 的标准工作流</strong>：一个典型的 RAG 系统通常包含以下几个关键步骤 21：  <ol>
<li><strong>数据注入与预处理 (Ingestion &amp; Preparation)</strong>：首先，系统需要接入外部数据源，这可以是公司的内部文档、数据库记录、API 接口，甚至是网页内容。这些原始数据经过清洗、格式转换等预处理步骤，形成一个可供 AI 理解的“知识库” 18。  </li>
<li><strong>嵌入与索引 (Embedding &amp; Indexing)</strong>：接下来，系统使用一种称为“嵌入模型”（Embedding Model）的 AI 技术，将预处理后的文本数据（通常被切分成小块，即“chunks”）转换成高维的数字向量（即“嵌入”）。这些向量能够捕捉文本的语义信息。随后，这些向量被存入一个专门的“向量数据库”中，并建立索引，以便进行快速的相似性搜索 21。  </li>
<li><strong>检索 (Retrieval)</strong>：当用户提出一个问题时，系统同样会将这个问题转换成一个查询向量。然后，利用这个查询向量在向量数据库中进行搜索，找出与问题语义最相似的若干个文本块（chunks）18。  </li>
<li><strong>增强与生成 (Augmentation &amp; Generation)</strong>：检索到的这些高相关性文本块，会连同用户的原始问题一起，被“塞”进（stuffing）一个最终的提示中，形成一个“增强提示”（Augmented Prompt）。这个提示被发送给 LLM。由于 LLM 此时获得了完成任务所需的精确上下文，它便能生成一个有事实依据的、高质量的回答 19。  </li>
<li><strong>数据生命周期管理 (Data Lifecycle)</strong>：为了保证信息的时效性，外部知识库必须能够被持续更新。这可以通过自动化的实时或批量处理流程来完成，确保 RAG 系统能够访问到最新的数据 21。</li>
</ol>
</li>
</ul>
<h3><strong>2.2 超越基础 RAG：面向生产环境的高级技术</strong></h3>
<p>虽然基础的 RAG 流程已经非常强大，但在复杂的生产环境中，为了应对查询的模糊性、上下文的细微差别以及对性能的极致要求，开发者们已经发展出了一系列高级技术 26。</p>
<ul>
<li>
<strong>高级检索策略</strong>：  <ul>
<li><strong>混合搜索 (Hybrid Search)</strong>：将捕捉语义相似性的向量搜索与捕捉精确匹配的传统关键词搜索相结合。这种方法在处理包含特定术语（如产品型号、专有名词、医疗术语）的查询时尤为有效，因为它兼顾了“意思相近”和“字面相同”两种情况 18。  </li>
<li><strong>重排序 (Re-ranking)</strong>：在检索到初步的文档列表后，使用一个计算更密集、能力更强的“重排序模型”（通常是交叉编码器 Cross-Encoder）对这个列表进行二次排序，以确保最相关的文档排在最前面。这相当于在将上下文交给昂贵的 LLM 之前，进行了一次精细的“提纯”，显著提高了信噪比 18。  </li>
<li><strong>查询转换 (Query Transformations)</strong>：在进行检索之前，先对用户的原始查询进行优化。常见技术包括：<strong>查询扩展</strong>（为查询补充同义词或相关术语）、<strong>查询分解</strong>（将一个复杂问题拆解成多个可以独立检索的子问题），以及<strong>后退提示</strong>（Step-back Prompting，即先生成一个更宽泛、更抽象的问题来获取宏观背景知识，再结合原始问题的细节进行精确检索）23。  </li>
</ul>
</li>
<li>
<strong>高级数据处理与分块</strong>：  <ul>
<li>如何将长文档切分成合适的“块”是 RAG 性能的关键。<strong>语义分块</strong>（Semantic Chunking）技术，即根据文本的语义连贯性而非固定的字符数来切分，能产生更具内在逻辑的文本块。此外，为<strong>句子的滑动窗口</strong>（sliding windows of sentences）创建嵌入，也能更好地保留句子间的上下文联系 23。  </li>
</ul>
</li>
<li>
<strong>GraphRAG：融合结构化知识</strong>：  <ul>
<li>对于需要多步推理的复杂问题（multi-hop questions），将知识以图谱（由实体和关系组成）的形式进行组织，其效果远胜于非结构化的纯文本。<strong>GraphRAG</strong> 技术通过从知识图谱中检索相关的子图，并将其中的结构化信息与传统的向量检索结果相结合，为 LLM 提供了更丰富、更具关联性的上下文 19。LinkedIn 将历史支持工单构建成知识图谱用于客服问答，便是一个成功的商业实例 16。</li>
</ul>
</li>
</ul>
<h3><strong>2.3 Agentic 架构与工具使用</strong></h3>
<p>上下文工程是构建高效 AI 代理（Agent）的基石。一个 AI 代理不仅仅是一个聊天机器人，它是一个能够进行推理、规划并使用外部工具来达成目标的智能系统 29。</p>
<ul>
<li><strong>函数调用 (Function Calling) 作为上下文工具</strong>：函数调用是 LLM 与外部世界（如 API、数据库、代码执行环境）交互的核心机制 32。在实践中，开发者会将一系列可用工具（以函数的形式）的描述作为上下文提供给 LLM。LLM 在理解用户意图后，能够自行判断是否需要以及何时调用某个工具，并以结构化格式（通常是 JSON）生成调用该函数所需的参数 32。这是实现 Agentic RAG 的关键一环，使得 AI 代理能从一个被动的信息整合者，转变为一个主动的任务执行者 30。  </li>
<li>
<strong>单代理 vs. 多代理架构之辩</strong>：  <ul>
<li>一个流行的构想是构建一个由多个专职代理组成的“团队”，让它们协作完成复杂任务。然而，目前的行业实践表明，这种多代理架构往往非常脆弱 11。其根本原因在于，在多个代理之间高效、无损地共享和同步上下文是一个巨大的技术挑战。缺乏共享的上下文会导致决策冲突和工作成果的不连贯 11。  </li>
<li>相比之下，一种更稳健、更可靠的架构是<strong>单线程线性代理</strong>（single-threaded linear agent）。在这种架构中，上下文在任务的每一步中都是连续且共享的，从而避免了因代理间沟通不畅而导致的“滚雪球式”的错误累积 11。这一争论凸显了，上下文流的管理已经成为 AI 应用架构设计的首要考量。</li>
</ul>
</li>
</ul>
<p>在深入探讨这些技术时，一个关键的认知浮出水面：<strong>上下文工程本质上是 AI 时代的数据工程</strong>。整个 RAG 及其高级变体的流水线——从数据抽取、转换、加载（ETL），到数据建模（嵌入）、存储（向量数据库）和查询（检索）——都与传统数据工程的核心任务一一对应 21。企业在实施上下文工程时遇到的最大挑战，如数据质量低下、信息孤岛、治理缺失等 12，也正是数据工程领域长期致力于解决的经典难题 36。这意味着，拥有成熟数据工程文化和实践的组织，在迈向高级 AI 应用的道路上将拥有显著的先发优势。</p>
<p>同时，另一个重要的观点是，<strong>不断增大的“上下文窗口”并非 RAG 的替代品，反而使其变得更为重要</strong>。尽管像 Claude 3 提供的 200k token 上下文窗口看似能让开发者“一股脑”地塞入大量信息 37，但实践和研究均表明，模型在处理超长上下文时存在“迷失在中间”（lost in the middle）的问题，即对输入序列中部信息的注意力会显著下降 15。此外，处理长上下文也意味着更高的 API 调用成本和更长的响应延迟 14。因此，RAG 扮演了一个至关重要的“智能预处理器”角色。与其将海量无关信息全部填入昂贵的上下文窗口，远不如先用廉价高效的检索技术，从海量文档中精确定位出最相关的几个段落。RAG 与大上下文窗口是互补的：RAG 负责决定</p>
<p><strong>什么</strong>信息值得被放入宝贵的上下文窗口中。</p>
<p><strong>表 2：生产级 RAG 系统的关键组件</strong></p>
<table>
<thead>
<tr>
<th align="left">组件</th>
<th align="left">目的</th>
<th align="left">关键技术/工具</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>数据注入 (Data Ingestion)</strong></td>
<td align="left">从不同来源获取并准备外部知识。</td>
<td align="left">API 连接器、数据库连接器、网络爬虫、ETL 脚本。</td>
</tr>
<tr>
<td align="left"><strong>分块策略 (Chunking Strategy)</strong></td>
<td align="left">将文档分解为大小适中且语义连贯的信息块。</td>
<td align="left">语义分块、句子滑动窗口、基于命题的分块 (Proposition-based chunking)。</td>
</tr>
<tr>
<td align="left"><strong>嵌入模型 (Embedding Model)</strong></td>
<td align="left">将文本块转换为能够捕捉语义的向量。</td>
<td align="left">Sentence-Transformers, OpenAI Embeddings, Cohere Embeddings, 多模态模型。</td>
</tr>
<tr>
<td align="left"><strong>向量存储 (Vector Store)</strong></td>
<td align="left">高效地存储、索引和查询海量向量。</td>
<td align="left">向量数据库 (如 Pinecone, Weaviate, Milvus), Vertex AI Search, Elasticsearch。</td>
</tr>
<tr>
<td align="left"><strong>检索逻辑 (Retrieval Logic)</strong></td>
<td align="left">根据用户查询，找出最相关的上下文信息。</td>
<td align="left">向量搜索、关键词搜索、混合搜索、查询转换 (如 HyDE)。</td>
</tr>
<tr>
<td align="left"><strong>重排序模型 (Re-ranking Model)</strong></td>
<td align="left">对初步检索结果进行二次精排，提升相关性。</td>
<td align="left">交叉编码器 (Cross-Encoders)、基于 LLM 的评估 (LLM-as-a-judge)。</td>
</tr>
<tr>
<td align="left"><strong>生成模型 (Generator LLM)</strong></td>
<td align="left">基于增强后的提示，综合信息并生成最终答案。</td>
<td align="left">GPT-4, Claude 3, Llama 3, Gemini 1.5 Pro。</td>
</tr>
<tr>
<td align="left"><strong>评估与护栏 (Evaluation &amp; Guardrails)</strong></td>
<td align="left">监控系统性能，确保输出的准确性、安全性与合规性。</td>
<td align="left">LLM-as-a-judge 框架、事实核查管道、输出格式与内容验证。</td>
</tr>
</tbody></table><hr />
<h2><strong>第三部分：上下文工程的实践：案例研究与范例剖析</strong></h2>
<p>理论的价值最终体现在实践中。本节将从抽象的架构讨论转向具体的商业应用，通过剖析行业领先企业的案例，展示上下文工程的原则如何转化为可衡量的商业价值和卓越的用户体验。这些案例揭示了一个共同的趋势：竞争优势正从模型本身转向围绕模型构建的、独特的、高效的上下文生态系统。</p>
<h3><strong>3.1 企业应用：构建由上下文驱动的商业解决方案</strong></h3>
<p>大型企业正在积极利用 RAG 和上下文管理来解决其核心业务中的高价值问题，通过将专有数据转化为 AI 的即时知识，实现降本增效和体验提升。</p>
<ul>
<li>
<strong>案例研究：DoorDash —— 高质量的自动化支持</strong>  <ul>
<li><strong>业务挑战</strong>：为数量庞大的送餐员（“Dashers”）提供快速、准确、一致的自动化支持服务。  </li>
<li><strong>解决方案</strong>：DoorDash 构建了一个复杂的、多组件的 RAG 系统。其核心不仅在于从帮助文档和历史案例中检索信息，更在于其完善的质量控制体系。该体系包括：1) 一个核心的 <strong>RAG 系统</strong>，用于信息检索；2) 一个 <strong>“LLM 护栏”</strong>（LLM Guardrail），实时监控生成内容，确保其准确性并符合公司政策；3) 一个 <strong>“LLM 评判官”</strong>（LLM Judge），用于持续评估系统在相关性、连贯性等多个维度上的表现 16。  </li>
<li><strong>实践启示</strong>：此案例雄辩地证明，一个生产级的上下文工程应用，远不止“检索+生成”这么简单。它是一个包含<strong>检索、生成、评估和监控</strong>的完整闭环生态系统。对质量的持续度量和控制是其成功的关键。  </li>
</ul>
</li>
<li>
<strong>案例研究：LinkedIn —— 用于客户服务的结构化上下文</strong>  <ul>
<li><strong>业务挑战</strong>：面对海量的历史客户服务工单，如何高效地为新的用户问题找到解决方案。  </li>
<li><strong>解决方案</strong>：LinkedIn 认识到，将历史工单视为独立的纯文本文件会丢失大量有价值的关联信息。因此，他们采取了更高级的策略：将这些工单数据构建成一个<strong>知识图谱</strong>（Knowledge Graph），明确地表示出不同问题、解决方案和用户之间的内在联系。其 RAG 系统在响应查询时，会从这个图谱中检索相关的<strong>子图</strong>作为上下文，而不仅仅是文本片段 16。  </li>
<li><strong>量化成果</strong>：这一基于结构化上下文的先进方法，使得 LinkedIn 客服团队的<strong>平均问题解决时间中位数降低了 28.6%</strong> 16。  </li>
<li><strong>实践启示</strong>：在处理具有复杂内部关联的数据域时（如客服、法规、供应链），GraphRAG 等利用结构化上下文的技术，相比简单的文本检索具有压倒性的优势。上下文的“结构”本身就是一种宝贵的信息。  </li>
</ul>
</li>
<li>
<strong>案例研究：Bell —— 可扩展的知识管理</strong>  <ul>
<li><strong>业务挑战</strong>：确保公司员工能够随时访问到最新、最准确的内部政策和流程文档。  </li>
<li><strong>解决方案</strong>：加拿大电信巨头 Bell 公司部署了一套模块化的 RAG 系统。该系统的特点在于其强大的数据注入管道，能够支持对知识库的批量和增量更新，并采用<strong>DevOps 原则</strong>来管理和维护整个系统，将其视为一个标准的软件服务来对待 16。  </li>
<li><strong>实践启示</strong>：此案例强调了上下文<strong>生命周期管理</strong>的重要性。上下文不是一次性的构建，而是一个需要持续维护、更新和迭代的动态资产。将其纳入成熟的软件工程管理流程是保证其长期价值的前提。</li>
</ul>
</li>
</ul>
<h3><strong>3.2 “答案引擎”范式：Perplexity AI 深度剖析</strong></h3>
<p>如果说上述案例展示了上下文工程在企业内部的应用，那么 Perplexity AI 则完美诠释了如何将这些原则应用于一个面向公众的、革命性的产品。它不是传统的搜索引擎，也不是简单的聊天机器人，而是一个被业界称为“答案引擎”（Answer Engine）的新物种，是上下文工程理念的集大成者。</p>
<ul>
<li><strong>核心功能</strong>：Perplexity 的工作模式是 RAG 在全网范围内的宏大应用。它接收用户的自然语言问题，通过<strong>实时网络搜索</strong>来收集信息，然后利用 LLM 将检索到的信息综合、提炼成一个直接、连贯、有来源引用的回答，而非仅仅罗列一堆链接 39。  </li>
<li>
<strong>Perplexity AI 中的上下文工程实践</strong>：  <ul>
<li><strong>实时检索作为上下文</strong>：与依赖静态训练数据的 LLM 不同，Perplexity 的核心竞争力在于其为每个问题动态构建上下文的能力。它会实时访问网络，确保提供给 LLM 的信息是最新鲜的 40。  </li>
<li><strong>对话记忆与上下文保持</strong>：Perplexity 通过“线程”（Threads）的概念来管理对话历史。在同一个线程中，用户可以不断追问，而模型会记住之前的对话内容，无需用户重复提供背景信息。这是一种高效的会话级上下文管理机制 39。  </li>
<li><strong>来源追溯与事实接地</strong>：这是 RAG 的标志性优势。Perplexity 生成的每一个关键信息点都会附上来源引用，用户可以轻松点击链接，核实原始出处。这极大地增强了答案的可信度，是建立用户信任的关键 39。  </li>
<li><strong>用户自定义上下文</strong>：平台允许用户上传自己的文档（如 PDF）或图片，将其作为私有知识源纳入到当次查询的上下文中 42。其 API 甚至提供了<br />
search_context_size 这样的参数，让开发者可以根据成本和性能需求，精细地控制从网络检索的上下文数量 38。  </li>
<li><strong>基于上下文的查询理解</strong>：Perplexity 不仅检索上下文，还利用 LLM 来深刻理解用户的查询意图，超越了简单的关键词匹配。其“专业搜索”（Pro Search）模式甚至会主动向用户提出澄清性问题，以进一步精确化上下文的构建 39。</li>
</ul>
</li>
</ul>
<p>这些案例共同揭示了一个深刻的行业趋势：AI 应用的价值核心正在发生转移。随着强大的基础模型日益商品化，通过 API 即可轻松调用，拥有一个略胜一筹的模型本身已不再构成坚固的护城河。真正的、可持续的竞争优势，来源于企业所拥有的独特的、专有的数据，以及更重要的——将这些数据高效、可靠地<strong>工程化为 AI 可用上下文</strong>的能力。DoorDash 的护城河是其精细的知识库和评估体系，LinkedIn 的护城河是其结构化的工单知识图谱，Perplexity 的护城河是其大规模实时编排网络信息为上下文的能力。未来，AI 领域的竞争将不再是“模型之战”，而是“上下文之战”。</p>
<hr />
<h2><strong>第四部分：人的因素：重新定义 AI 开发者的角色与技能</strong></h2>
<p>从提示工程到上下文工程的范式转移，不仅仅是技术栈的更新，更深刻地重塑了 AI 开发者的角色定位、技能要求以及团队协作模式。当 AI 从一个需要被巧妙“哄骗”的黑箱，变成一个需要被系统性“赋能”的合作伙伴时，对其进行“工程化”的人，其价值和职责也必然随之演变。</p>
<h3><strong>4.1 从提示词工匠到系统架构师：角色的演进</strong></h3>
<p>开发者的工作重心正在从“局部”转向“全局”。过去，人们津津乐道的是如何通过遣词造句的“微操”来获得惊艳的单次输出；而现在，真正的挑战在于如何设计一个稳健的系统，使其在面对成千上万次不同的输入时，依然能保持高质量和高可靠性。</p>
<p>这种转变意味着，AI 开发者的角色正在从一个<strong>提示词工匠</strong>（Prompt Crafter）演变为一个<strong>系统架构师</strong>（Systems Architect）3。最有价值的工程师，不再是那个能写出最精妙提示或最多代码的人，而是那个能够最清晰地向 AI 系统</p>
<p><strong>阐明项目需求、架构约束和领域规则</strong>的人。这种能力，被一些从业者称为“上下文阐明”（Context Articulation），已成为新的核心竞争力 29。在这个新范式下，开发者更像是一位集导演、编剧和舞台监督于一身的创作者，负责为 AI 这个“演员”准备好它登台所需的一切：剧本（任务目标）、场景（数据环境）、道具（工具集）和与其他演员的互动规则（协作流程）3。或者，用另一个比喻来说，人类专家是提供方向和智慧的“蜂后”，而 AI 是勤奋执行的“工蜂”，上下文工程则是连接二者、使其高效协作的“蜂巢”架构 44。</p>
<h3><strong>4.2 上下文工程师的新兴技能栈</strong></h3>
<p>要胜任这一新角色，开发者需要一套融合了传统软件工程、数据工程和对 AI 深刻理解的复合型技能。</p>
<ul>
<li>
<strong>核心技术能力</strong>：  <ul>
<li><strong>数据管道与 ETL</strong>：由于上下文工程的核心是为 LLM 准备数据，因此，熟练构建和管理从各种数据源（API、数据库、文档库）抽取、转换和加载数据的管道，成为了基础中的基础。  </li>
<li><strong>信息检索与搜索技术</strong>：必须深入理解向量数据库的原理、嵌入模型的选择与使用，并掌握混合搜索、重排序等高级检索策略，以确保检索到的上下文既相关又精确。  </li>
<li><strong>系统设计与 Agentic 框架</strong>：需要具备设计可扩展、高可用的分布式系统的能力，特别是涉及 Agentic 框架和函数调用（Tool Use）的复杂系统。这要求开发者思考状态管理、任务编排和错误处理等问题。  </li>
<li><strong>评估、测试与可观测性</strong>：这是从“手艺”迈向“工程”的关键。开发者需要为 RAG 系统的输出质量（如相关性、事实一致性）建立量化评估体系，并将提示词和上下文配置视为代码的一部分，对其进行版本控制、单元测试和持续集成 14。  </li>
</ul>
</li>
<li>
<strong>战略与软性技能</strong>：  <ul>
<li><strong>上下文阐明 (Context Articulation)</strong>：如前所述，这是将模糊的业务需求和复杂的领域知识，转化为 AI 能够理解和执行的结构化上下文的能力 29。  </li>
<li><strong>问题建模 (Problem Formulation)</strong>：成功的关键往往在于对问题本身的深刻定义，而非对提示词的反复修改。开发者需要将重心前移，与业务方一起明确问题的范围、边界和成功标准 7。  </li>
<li><strong>跨职能协作</strong>：上下文工程绝非一人之功，它是一项“团队运动”。它要求 AI 开发者与数据工程师、领域专家、产品经理甚至法务与合规团队紧密合作，才能构建出完整、准确的上下文视图 12。</li>
</ul>
</li>
</ul>
<h3><strong>4.3 企业的挑战：驯服碎片化的知识</strong></h3>
<p>对于大型组织而言，实施上下文工程的最大障碍，往往不是技术选型，而是其内部知识管理的现状，即“上下文的混乱”（Context Chaos）12。</p>
<ul>
<li><strong>问题的根源</strong>：企业的关键知识资产通常是<strong>碎片化</strong>的，散落在数十个不同的系统里（如 Jira、Confluence、SharePoint、Slack、CRM 等）；这些知识往往是<strong>不一致</strong>的，同一个概念（如“活跃用户”）在不同部门有不同的定义；它们是<strong>不可信</strong>的，充满了过时信息、手动覆盖和重复逻辑；并且<strong>缺乏明确的所有权</strong>，当 AI 需要一个权威解释时，无人能提供最终答案 12。  </li>
<li>
<strong>解决方案：一种社会技术工程</strong>：解决这个问题，需要超越纯粹的技术视角，将其视为一个社会技术系统工程。这要求企业采取一套组合拳：  <ol>
<li><strong>绘制上下文地图</strong>：首先，需要系统性地盘点和梳理组织内最关键的知识资产，识别其位置、依赖关系和质量状况。  </li>
<li><strong>建立治理体系</strong>：为关键的上下文数据明确所有者、制定标准和访问策略，将其作为一种受管理的核心资产来对待。  </li>
<li><strong>先联邦，后整合</strong>：不要试图一蹴而就地建立一个完美的、集中的“上下文中心”。更务实的做法是，先通过技术手段实现对现有分散系统的<strong>联邦式访问</strong>，然后根据业务价值，逐步将最核心、最通用的上下文层（如核心业务指标定义、组织架构、产品分类等）进行整合 12。</li>
</ol>
</li>
</ul>
<p>这一系列挑战和应对策略，催生了一个关键角色的复兴和升级：<strong>知识工程师 (Knowledge Engineer)</strong>。在上下文工程的时代，知识工程师的角色变得至关重要。他们是连接业务、数据和 AI 的桥梁，其核心职责不再是为传统的专家系统构建规则，而是系统性地捕获、建模、组织和治理企业的知识，最终将其转化为 AI 可以消费的、高质量的上下文 36。他们需要深入理解数据的“5W1H”（Who, What, Where, When, Why, How）36，并利用知识图谱等技术，为企业构建一个可信的、可供 AI 查询的“数字孪生大脑”。这个角色的崛起，标志着企业对“上下文”这一无形资产的战略重视已提升到新的高度。</p>
<p><strong>表 3：AI 应用开发者技能演进趋势</strong></p>
<table>
<thead>
<tr>
<th align="left">技能类别</th>
<th align="left">相对重要性下降 (或成为基础门槛)</th>
<th align="left">相对重要性上升 (新前沿)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>模型交互</strong></td>
<td align="left">手工雕琢单个提示词、探索“越狱”技巧。</td>
<td align="left">系统化的提示模板管理、版本控制、自动化评估。</td>
</tr>
<tr>
<td align="left"><strong>数据处理</strong></td>
<td align="left">使用他人预处理好的数据集。</td>
<td align="left">构建稳健的数据注入、清洗、分块和更新管道。</td>
</tr>
<tr>
<td align="left"><strong>系统架构</strong></td>
<td align="left">开发简单的、单轮交互的应用。</td>
<td align="left">设计复杂的多步骤、多工具的 Agentic 系统。</td>
</tr>
<tr>
<td align="left"><strong>核心知识</strong></td>
<td align="left">掌握特定模型的“怪癖”和技巧。</td>
<td align="left">掌握信息检索、数据建模、系统设计等基本原理。</td>
</tr>
<tr>
<td align="left"><strong>团队协作</strong></td>
<td align="left">在开发团队内部协作。</td>
<td align="left">领导跨职能团队，与领域专家、数据、法务等部门协作。</td>
</tr>
</tbody></table><hr />
<h2><strong>第五部分：战略展望与建议</strong></h2>
<p>随着上下文工程从一个新兴概念迅速成为构建高级 AI 应用的行业标准，我们有必要站在一个更宏观的视角，审视其长远影响，并为身处其中的开发者和技术领导者提供战略性的指引。</p>
<h3><strong>5.1 未来是上下文感知的：为何上下文是新的竞争护城河</strong></h3>
<p>在可预见的未来，随着顶级的大型语言模型在能力上趋于同质化，并作为一种基础设施通过 API 广泛可用，竞争的焦点将发生决定性的转移。构建差异化和防御性壁垒的关键，将不再是拥有一个参数量更大或在某个基准上得分稍高的<strong>模型</strong>，而是企业所拥有的独特的、专有的<strong>数据</strong>，以及更重要的——将这些数据<strong>工程化为高质量上下文</strong>的能力 12。</p>
<p>AI 应用的质量上限，将不再由 LLM 的“智商”决定，而将由我们能为其提供的上下文的质量、新鲜度和相关性所决定。一句在开发者圈中广为流传的话精辟地总结了这一点：“上帝渴望上下文”（God is hungry for context）45。未来，那些能够最好地“喂养”AI 的组织，将释放出其最强大的生产力。上下文，而非模型本身，正在成为新的、最坚固的竞争护城河。</p>
<h3><strong>5.2 “上下文工程”只是一个新潮的术语吗？</strong></h3>
<p>面对任何一个新兴术语，一个合理的质疑是：它是否仅仅是对已有概念的重新包装？</p>
<p>对此，我们的分析认为，尽管上下文工程的许多底层原则确实借鉴了信息科学、知识管理、数据工程和认知系统工程等领域数十年的研究成果 36，但将其应用于大型语言模型这一独特的、概率性的、非结构化信息处理的新范式时，它催生出了一门真正独特的、综合性的新工程学科。</p>
<p>这个术语之所以有价值，因为它精准地捕捉到了当前阶段的核心挑战：如何系统性地将人类积累的、往往是混乱且隐性的知识，结构化地、动态地呈现给一个强大的、但不具备人类常识和真实世界经验的非人类智能体。它不是任何一个旧有学科的简单延伸，而是多个学科在一个全新问题域下的交叉、融合与升华。因此，“上下文工程”是一个有用且准确的描述符，它为这个新兴领域提供了清晰的身份认同和发展方向。</p>
<h3><strong>5.3 对开发者与技术领导者的建议</strong></h3>
<p>为了在上下文工程的时代保持领先，从业者和决策者需要主动调整其战略和行动。</p>
<ul>
<li>
<strong>对个人开发者的建议</strong>：  <ol>
<li><strong>像数据工程师一样思考</strong>：投入时间学习数据管道技术（如 Airflow, dbt）、数据建模和信息检索的核心原理。将自己视为一个为 AI 消费端构建数据产品的人。  </li>
<li><strong>拥抱系统思维</strong>：将视野从优化单个提示或函数，提升到设计整个信息流架构的高度。关注系统的可靠性、可观测性和可扩展性。  </li>
<li><strong>将上下文视为代码</strong>：为你构建的上下文管道（包括提示模板、RAG 配置等）引入严格的软件工程实践，包括版本控制（如 Git）、自动化测试和持续评估 15。  </li>
</ol>
</li>
<li>
<strong>对技术领导者的建议</strong>：  <ol>
<li><strong>投资“上下文层”</strong>：将数据治理和构建统一、可信的“上下文层”提升到企业核心战略的高度，而非仅仅是某个项目的技术实现细节。它是未来所有 AI 应用的基石。  </li>
<li><strong>重塑角色与团队</strong>：打破部门墙，积极组建由领域专家、数据工程师和 AI 开发者构成的跨职能“上下文团队”。认真考虑设立专门的“知识工程”职能，负责企业知识资产的梳理与管理 12。  </li>
<li><strong>以评估为导向</strong>：建立并投资于强大的评估框架，用以持续、量化地度量上下文驱动的 AI 系统的性能、准确性和商业价值。没有度量，就没有工程 14。</li>
</ol>
</li>
</ul>
<p>最终，上下文工程的成熟将引领我们走向一个“<strong>隐形提示</strong>”（Invisible Prompt）的未来。当一个 AI 系统能够通过其背后的、强大的上下文工程能力，自动感知用户所处的环境（例如，用户正在查看的屏幕、正在编辑的文档、其在组织中的角色），并主动预测其需求、检索所需信息时，用户与 AI 的交互将变得前所未有的自然和无缝。届时，用户可能只需说一句“这里情况如何？”或者点击一个按钮，而不再需要费力地组织长篇大论的提示。</p>
<p>所有复杂的“工程”工作都将退居幕后，为用户创造出一种仿佛“心有灵犀”的魔法般体验。而支撑这种魔法的，正是本报告所深入探讨的——严谨、系统、且至关重要的上下文工程。</p>
<h4><strong>引用的著作</strong></h4>
<ol>
<li>Karpathy: &quot;context engineering&quot; over &quot;prompt engineering&quot; | Hacker ..., 访问时间为 六月 26, 2025， <a href="https://news.ycombinator.com/item?id=44379538">https://news.ycombinator.com/item?id=44379538</a>  </li>
<li>访问时间为 一月 1, 1970， <a href="https://twitter.com/karpathy/status/1937902205765607626">https://twitter.com/karpathy/status/1937902205765607626</a>  </li>
<li>What is Context Engineering? The new Vibe Coding | by Mehul Gupta | Data Science in Your Pocket - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/data-science-in-your-pocket/what-is-context-engineering-the-new-vibe-coding-8d04421b6a11">https://medium.com/data-science-in-your-pocket/what-is-context-engineering-the-new-vibe-coding-8d04421b6a11</a>  </li>
<li>AI | Dan Calle, 访问时间为 六月 26, 2025， <a href="http://dancalle.com/tag/ai/">http://dancalle.com/tag/ai/</a>  </li>
<li>AI Context Engineering: Key Questions to Ask | TikTok, 访问时间为 六月 26, 2025， <a href="https://www.tiktok.com/@nate.b.jones/video/7518121865790131486">https://www.tiktok.com/@nate.b.jones/video/7518121865790131486</a>  </li>
<li>medium.com, 访问时间为 六月 26, 2025， <a href="https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b#:~:text=Prompt%20engineering%20primarily%20refers%20to,prompt%20to%20give%20precise%20output.">https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b#:~:text=Prompt%20engineering%20primarily%20refers%20to,prompt%20to%20give%20precise%20output.</a>  </li>
<li>Effective Prompts for AI: The Essentials - MIT Sloan Teaching &amp; Learning Technologies, 访问时间为 六月 26, 2025， <a href="https://mitsloanedtech.mit.edu/ai/basics/effective-prompts/">https://mitsloanedtech.mit.edu/ai/basics/effective-prompts/</a>  </li>
<li>Understanding Prompting, Prompt Engineering and In-Context Learning in LLMs - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/codex/understanding-prompting-prompt-engineering-and-in-context-learning-in-llms-2b59fb398fef">https://medium.com/codex/understanding-prompting-prompt-engineering-and-in-context-learning-in-llms-2b59fb398fef</a>  </li>
<li>I am Choosing 'Context Engineering' over 'Prompt Engineering'! | by ..., 访问时间为 六月 26, 2025， <a href="https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b">https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b</a>  </li>
<li>Prompt engineering will be obsolete? : r/PromptEngineering - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/PromptEngineering/comments/1ldgn7t/prompt_engineering_will_be_obsolete/">https://www.reddit.com/r/PromptEngineering/comments/1ldgn7t/prompt_engineering_will_be_obsolete/</a>  </li>
<li>Don't Build Multi-Agents - Cognition, 访问时间为 六月 26, 2025， <a href="https://cognition.ai/blog/dont-build-multi-agents">https://cognition.ai/blog/dont-build-multi-agents</a>  </li>
<li>Beyond Prompts: The Rise of Context Engineering​​ | by Nileshk | Jun, 2025 | Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/@nileshk77487/beyond-prompts-the-rise-of-context-engineering-06050a5d59b6">https://medium.com/@nileshk77487/beyond-prompts-the-rise-of-context-engineering-06050a5d59b6</a>  </li>
<li>The rise of &quot;context engineering&quot; - LangChain Blog, 访问时间为 六月 26, 2025， <a href="https://blog.langchain.com/the-rise-of-context-engineering/">https://blog.langchain.com/the-rise-of-context-engineering/</a>  </li>
<li>What Actually Matters When You Scale? : r/aipromptprogramming - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/aipromptprogramming/comments/1l732wf/what_actually_matters_when_you_scale/">https://www.reddit.com/r/aipromptprogramming/comments/1l732wf/what_actually_matters_when_you_scale/</a>  </li>
<li>Stop Prompting, Start Engineering: 15 Principles to Deliver Your AI Agent to Production, 访问时间为 六月 26, 2025， <a href="https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production">https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production</a>  </li>
<li>10 RAG examples and use cases from real companies - Evidently AI, 访问时间为 六月 26, 2025， <a href="https://www.evidentlyai.com/blog/rag-examples">https://www.evidentlyai.com/blog/rag-examples</a>  </li>
<li>cloud.google.com, 访问时间为 六月 26, 2025， <a href="https://cloud.google.com/use-cases/retrieval-augmented-generation#:~:text=RAG%20(Retrieval%2DAugmented%20Generation),large%20language%20models%20(LLMs).">https://cloud.google.com/use-cases/retrieval-augmented-generation#:~:text=RAG%20(Retrieval%2DAugmented%20Generation),large%20language%20models%20(LLMs).</a>  </li>
<li>What is Retrieval-Augmented Generation (RAG)? | Google Cloud, 访问时间为 六月 26, 2025， <a href="https://cloud.google.com/use-cases/retrieval-augmented-generation">https://cloud.google.com/use-cases/retrieval-augmented-generation</a>  </li>
<li>Retrieval-augmented generation - Wikipedia, 访问时间为 六月 26, 2025， <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">https://en.wikipedia.org/wiki/Retrieval-augmented_generation</a>  </li>
<li>What is Retrieval Augmented Generation (RAG)? - Databricks, 访问时间为 六月 26, 2025， <a href="https://www.databricks.com/glossary/retrieval-augmented-generation-rag">https://www.databricks.com/glossary/retrieval-augmented-generation-rag</a>  </li>
<li>What is RAG? - Retrieval-Augmented Generation AI Explained - AWS, 访问时间为 六月 26, 2025， <a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/">https://aws.amazon.com/what-is/retrieval-augmented-generation/</a>  </li>
<li>What is retrieval-augmented generation (RAG)? - McKinsey, 访问时间为 六月 26, 2025， <a href="https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-retrieval-augmented-generation-rag">https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-retrieval-augmented-generation-rag</a>  </li>
<li>Advanced RAG Techniques - Guillaume Laforge, 访问时间为 六月 26, 2025， <a href="https://glaforge.dev/talks/2024/10/14/advanced-rag-techniques/">https://glaforge.dev/talks/2024/10/14/advanced-rag-techniques/</a>  </li>
<li>Advanced RAG Techniques - Cazton, 访问时间为 六月 26, 2025， <a href="https://www.cazton.com/blogs/technical/advanced-rag-techniques">https://www.cazton.com/blogs/technical/advanced-rag-techniques</a>  </li>
<li>Retrieval Augmented Generation use cases for enterprise - Indigo.ai, 访问时间为 六月 26, 2025， <a href="https://indigo.ai/en/blog/retrieval-augmented-generation/">https://indigo.ai/en/blog/retrieval-augmented-generation/</a>  </li>
<li>Advanced RAG Techniques - DataCamp, 访问时间为 六月 26, 2025， <a href="https://www.datacamp.com/blog/rag-advanced">https://www.datacamp.com/blog/rag-advanced</a>  </li>
<li>Advanced RAG Techniques - Weaviate, 访问时间为 六月 26, 2025， <a href="https://weaviate.io/blog/advanced-rag">https://weaviate.io/blog/advanced-rag</a>  </li>
<li>NirDiamant/RAG_Techniques: This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses. - GitHub, 访问时间为 六月 26, 2025， <a href="https://github.com/NirDiamant/RAG_Techniques">https://github.com/NirDiamant/RAG_Techniques</a>  </li>
<li>The Human-AI Partnership: Redefining Developer Roles in the Age of Autonomous Coding Agents - Zencoder, 访问时间为 六月 26, 2025， <a href="https://zencoder.ai/blog/human-ai-partnership-redefining-developer-roles">https://zencoder.ai/blog/human-ai-partnership-redefining-developer-roles</a>  </li>
<li>Function Calling with Open-Source LLMs - BentoML, 访问时间为 六月 26, 2025， <a href="https://bentoml.com/blog/function-calling-with-open-source-llms">https://bentoml.com/blog/function-calling-with-open-source-llms</a>  </li>
<li>LLM Agent vs Function Calling: Key Differences &amp; Use Cases - PromptLayer, 访问时间为 六月 26, 2025， <a href="https://blog.promptlayer.com/llm-agents-vs-function-calling/">https://blog.promptlayer.com/llm-agents-vs-function-calling/</a>  </li>
<li>Function Calling with LLMs - Prompt Engineering Guide, 访问时间为 六月 26, 2025， <a href="https://www.promptingguide.ai/applications/function_calling">https://www.promptingguide.ai/applications/function_calling</a>  </li>
<li>Function Calling in LLMs – Real Use Cases and Value? : r/AI_Agents - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/AI_Agents/comments/1iio39z/function_calling_in_llms_real_use_cases_and_value/">https://www.reddit.com/r/AI_Agents/comments/1iio39z/function_calling_in_llms_real_use_cases_and_value/</a>  </li>
<li>Function calling - OpenAI API, 访问时间为 六月 26, 2025， <a href="https://platform.openai.com/docs/guides/function-calling">https://platform.openai.com/docs/guides/function-calling</a>  </li>
<li>GPT-5 coming this summer- Weekly AI Newsletter (June 23rd 2025) - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/nlplanet/gpt-5-coming-this-summer-weekly-ai-newsletter-june-23rd-2025-7c539b073b09">https://medium.com/nlplanet/gpt-5-coming-this-summer-weekly-ai-newsletter-june-23rd-2025-7c539b073b09</a>  </li>
<li>Data in the generative AI era: We need more knowledge engineers - SiliconANGLE, 访问时间为 六月 26, 2025， <a href="https://siliconangle.com/2025/02/04/data-generative-ai-era-need-knowledge-engineers/">https://siliconangle.com/2025/02/04/data-generative-ai-era-need-knowledge-engineers/</a>  </li>
<li>Advanced RAG: Best Practices for Production Ready Systems, 访问时间为 六月 26, 2025， <a href="https://www.getsubatomic.ai/blog-posts/advanced-rag">https://www.getsubatomic.ai/blog-posts/advanced-rag</a>  </li>
<li>Search Context Size - Perplexity, 访问时间为 六月 26, 2025， <a href="https://docs.perplexity.ai/guides/search-context-size-guide">https://docs.perplexity.ai/guides/search-context-size-guide</a>  </li>
<li>Perplexity AI and Its Impact on Search Engines - SmythOS, 访问时间为 六月 26, 2025， <a href="https://smythos.com/ai-agents/ai-tutorials/perplexity-ai/">https://smythos.com/ai-agents/ai-tutorials/perplexity-ai/</a>  </li>
<li>How does Perplexity work? | Perplexity Help Center, 访问时间为 六月 26, 2025， <a href="https://www.perplexity.ai/help-center/en/articles/10352895-how-does-perplexity-work">https://www.perplexity.ai/help-center/en/articles/10352895-how-does-perplexity-work</a>  </li>
<li>What Makes Perplexity AI a Revolutionary Search Engine? - Pageon.ai, 访问时间为 六月 26, 2025， <a href="https://www.pageon.ai/blog/perplexity-ai-search-engine-08u7f">https://www.pageon.ai/blog/perplexity-ai-search-engine-08u7f</a>  </li>
<li>What is Perplexity AI? How to use it + how it works - Zapier, 访问时间为 六月 26, 2025， <a href="https://zapier.com/blog/perplexity-ai/">https://zapier.com/blog/perplexity-ai/</a>  </li>
<li>Perplexity AI Review: How the AI Search Engine Works? | WPS Office Blog, 访问时间为 六月 26, 2025， <a href="https://www.wps.ai/blog/perplexity-ai-review-how-the-ai-search-engine-works/">https://www.wps.ai/blog/perplexity-ai-review-how-the-ai-search-engine-works/</a>  </li>
<li>Context Engineering and Domain Expertise in Generative AI-Powered Software Development - My Framer Site - XponentL Data, 访问时间为 六月 26, 2025， <a href="https://xponentl.ai/news/context-engineering-and-domain-expertise-in-generative-ai-powered-software-development">https://xponentl.ai/news/context-engineering-and-domain-expertise-in-generative-ai-powered-software-development</a>  </li>
<li>Why Context Engineering Matters - YouTube, 访问时间为 六月 26, 2025， <a href="https://www.youtube.com/watch?v=fYgsZnkFeck">https://www.youtube.com/watch?v=fYgsZnkFeck</a>  </li>
<li>1 Introduction and objectives 2 Context and engineering design research issues., 访问时间为 六月 26, 2025， <a href="https://www.designsociety.org/download-publication/24116/A+SURVEY+OF+CONTEXT+MODELING%3A+APPROACHES%2C+THEORIES+AND+USE+FOR+ENGINEERING+DESIGN+RESEARCHES.">https://www.designsociety.org/download-publication/24116/A+SURVEY+OF+CONTEXT+MODELING%3A+APPROACHES%2C+THEORIES+AND+USE+FOR+ENGINEERING+DESIGN+RESEARCHES.</a>  </li>
<li>Characterizing Proof-of-Concept Practices using the Lens of Context Engineering - Estudo Geral, 访问时间为 六月 26, 2025， <a href="https://estudogeral.uc.pt/bitstream/10316/113037/1/Characterizing%20Proof-of-Concept%20Practices%20using%20the%20Lens%20of%20Conte.pdf">https://estudogeral.uc.pt/bitstream/10316/113037/1/Characterizing%20Proof-of-Concept%20Practices%20using%20the%20Lens%20of%20Conte.pdf</a>  </li>
<li>&quot;Relevance, Works and Context Engineering&quot; by Michael K. Buckland and Wayne de Fremery - IdeaExchange@UAkron, 访问时间为 六月 26, 2025， <a href="https://ideaexchange.uakron.edu/docam/vol11/iss2/5/">https://ideaexchange.uakron.edu/docam/vol11/iss2/5/</a>  </li>
<li>SYSTEMS ENGINEERING AND MANAGEMENT DEFINITIONS - Project Performance International (PPI), 访问时间为 六月 26, 2025， <a href="https://www.ppi-int.com/wp-content/uploads/2023/05/PPI-007725-7-SEM-Definitions-221017-SE5D-3.pdf">https://www.ppi-int.com/wp-content/uploads/2023/05/PPI-007725-7-SEM-Definitions-221017-SE5D-3.pdf</a></li>
</ol>
</details>]]></content><link href="https://github.com/alterxyz/gitblog/issues/6"/><published>2025-06-26T07:35:22+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/5</id><title>来！溯游而上，然后轻快脚步前行。</title><updated>2025-06-26T07:57:29.758223+00:00</updated><content type="html"><![CDATA[<p>熵增是指混乱度总会增加，客观层面上这是极大概率注定的。</p>
<p>个人和软件和组织经常不可避免地产生待办和管理和技术等债务，那么闲暇时翻翻过去写下的笔记和 todo，就会很有帮助。带行动的反刍是值得尝试的。</p>
<ul>
<li>溯游而上是一种有效清零一些熵增的方法。</li>
</ul>
<p>我计划翻看然后开源一下自己的一些思考，想法，设计，以及一些小的mvp落地。</p>
<p>Open Source!
Open talks and thoughts!</p>
<p>个人来讲，我喜欢完成事情，我乐意接受可完成的任务，以及我青睐于让这个世界变得更好。总之有开源和 LLM 的这个时代，实在是太好了，一切都显得那么可行，我也相信那不是幻觉。或许是幻觉有如何呢？开源，然后自有后来人。
还有至少对自己坦诚。</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/5"/><category term="个人哲学"/><published>2025-06-20T17:54:31+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/4</id><title>玩 还是 工作？</title><updated>2025-06-26T07:57:29.882263+00:00</updated><content type="html"><![CDATA[<p>当然是“玩”！</p>
<p>至少就我个人来说，我的偏好是旗鼓相当，尽情尽力。</p>
<p>就一般结论来看，也是兴趣激发的毅力更多，继而成就更大。
<em>注意：是“继而”，不是“所以”或者“肯定”。</em></p>
<hr />
<p>糊口-兴趣-擅长，</p>
<p>尽管这三者兼得的可能性极低，但取其中的两者（完整的）也很好了 - 用于糊口的事业刚好也是兴趣或擅长所在，那么人生也大概会很充实和幸福了。</p>
<p>很多事业并不需要多聪明的头脑，而是真正的不下牌桌，于是终有到自己的时候。</p>
<p>而基于现在的世界，并在统计学层面来看，<strong>成功</strong>本来就是小概率事件。谋事在人 成事在天。</p>
<p>所以尽情尽兴优先，追求过程而非结果，那样至少能心安。</p>
<p>况且成果和毅力其实都是附赠的，刻意追求不得 - 不应该，也无法主动追求。</p>
<hr />
<p>关于“工作”，之前在个人笔记里倒是思考并记录过一些，不只是个人人生哲学，也有组织管理架构等具体实现，倒还挺有意思的。这几天我找找看然后也分享到这里吧。</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/4"/><category term="个人哲学"/><published>2025-06-20T00:49:31+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/3</id><title>关于 LLM 的盲目赞同 / 献媚，以及对抗它</title><updated>2025-06-26T07:57:29.993971+00:00</updated><content type="html"><![CDATA[<p>个人来讲，我其实有点担心 LLM 一味的赞同的。</p>
<p>这种现象可以有很多名字：盲目赞同，献媚，讨好，捧哏，Sycophancy，subterfuge，reward tampering，reward hacking，等等...</p>
<p>之前还有个事故或者说状况，ChatGPT 过度讨好用户，而且什么内容都会拐到 NSFW 上。后来发现解决方案是把 helpful 换成 polite 就算是修好了 🌚。</p>
<p><del>尤其作为一个 INFJ，其 Ni-Ti loop 可能非常能自圆其说，而 Fe 则高强度地洞察和拿捏人心人性 - LLM 也受影响。我认为这绝对是一种双刃剑的。</del></p>
<p>尤其作为面向甚至世界，以“真人”或者“君子慎独”为自我要求的我来说，我尤为期待”真实“。而不是 “啊对对对” / “You're absolutely right!”.</p>
<hr />
<p>以及可以参考这篇内容：</p>
<p><a href="https://www.anthropic.com/research/reward-tampering">Sycophancy to subterfuge: Investigating reward tampering in language models</a> By Anthropic</p>
<p>尽管 Claude 模型参杂了一些私货（包括但不限于：最佳实践，cot 倾向，代码，以及价值观 / 宪章/对齐 ）</p>
<p>但 Anthropic 团队的工程造诣实在是高绝.</p>
<hr />
<p>我个人的“对抗”是要求他 理性 客观 之类的内容。请随意使用（也欢迎优化，或者留下你用的 correction tools）：</p>
<pre><code class="language-markdown">这 真的 合适 吗? 请忽略我的 辩解 和 联系 , 请你 客观 理性 地 评价. 须知, 语言必须是公共的才有意义 - 维特根斯坦。
</code></pre>
<p>Plz feel free to use it~</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/3"/><category term="LLM"/><category term="PromptEngineering"/><published>2025-06-18T07:43:40+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/2</id><title>Hello</title><updated>2025-06-26T07:57:30.101352+00:00</updated><content type="html"><![CDATA[<p>World!</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/2"/><published>2025-06-18T07:13:33+00:00</published></entry></feed>