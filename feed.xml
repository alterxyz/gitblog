<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/alterxyz/gitblog</id><title>RSS feed of alterxyz's gitblog</title><updated>2025-06-26T08:27:43.115486+00:00</updated><link href="https://github.com/alterxyz/gitblog"/><link href="https://raw.githubusercontent.com/alterxyz/gitblog/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><entry><id>https://github.com/alterxyz/gitblog/issues/7</id><title>关于指令遵循和上下文管理：解码 LLM 的“稀释”效应与企业级应用</title><updated>2025-06-26T08:27:43.571473+00:00</updated><content type="html"><![CDATA[<h1>稀释</h1>
<h2>超越“听话”：解码 LLM 的“稀释”效应与企业级应用</h2>
<p>大型语言模型（LLM）正以惊人的速度改变着我们与信息交互的方式。然而，当我们惊叹于 LLM 的强大能力时，是否曾深入思考过：LLM 真的完全“理解”并“遵循”了我们的指令吗？它们的输出，究竟是用户意图的忠实反映，还是模型自身“意志”的某种体现？“幻觉”又是如何产生的？</p>
<p>本文将围绕 LLM 的“指令遵循”展开深入探讨，揭示其多维度特性，并引入“稀释效应”的概念来解释 LLM 在处理复杂信息时的行为模式。我们将重点关注“稀释效应”如何影响 LLM 的企业级应用，并探讨如何通过工程化手段，实现更精准的控制和更可靠的结果，以及最终实现人机协同。</p>
<p>一、 指令的多维性：不只是用户的 Prompt</p>
<p>当我们向 LLM 发出一个指令（Prompt）时，我们通常期望它能准确理解我们的意图。但实际上，LLM 的行为并非仅仅由我们的 Prompt 决定。除了用户明确输入的指令外，LLM 还会受到至少以下两个方面的影响：</p>
<ol>
<li>模型提供商的预设：LLM 的训练数据、预设规则、以及模型提供商为确保模型安全、合规、高效而制定的各种“最佳实践”，都会潜移默化地影响 LLM 的输出。</li>
<li>模型的推理过程：特别是对于专门的推理模型（如 DeepSeek），它们在处理问题时会大量借鉴自身的预训练知识和推理策略，这可能导致最终输出偏离用户最初的意图。</li>
</ol>
<p>这种多维度“指令”的交织，使得 LLM 的行为变得复杂。理解这种复杂性，是构建可靠的企业级 LLM 应用的前提。</p>
<p>二、 “稀释效应”：理解 LLM 的“思考”过程</p>
<p>为了更好地理解 LLM 在处理多维度“指令”时的行为模式，我们可以引入“稀释效应”的概念。所谓“稀释”，是指在 LLM 的推理过程中，用户输入的原始指令，会被模型自身的预训练知识、推理策略以及模型提供商的预设等因素所“稀释”，导致最终输出偏离用户最初的预期。</p>
<p>我们可以将不同来源的信息类比为不同密度的物质：</p>
<ul>
<li>用户 Prompt: 密度最高，代表用户的核心意图，如同恒星，是系统的核心。</li>
<li>RAG 知识库: 密度中等，提供额外的上下文信息，如同行星，围绕恒星运转，提供补充信息。</li>
<li>模型自身的推理: 密度也较高, 且体量较大，如同星云，在系统中弥漫，影响着整个系统的状态。</li>
</ul>
<p>当这些不同“密度”的信息在 LLM 内部相互作用时，就可能出现“稀释效应”。用户的原始指令（恒星）可能被模型自身的推理（星云）所“遮蔽”或“扭曲”，导致最终输出的结果并非完全符合用户预期。</p>
<p>“稀释”的演进：从“人工稀释 1.0”到“模型稀释 1.0”</p>
<p>“稀释”效应并非一开始就存在。随着 LLM 技术的发展，“稀释”的形式也在不断演进：</p>
<ul>
<li>
<p>人工稀释 1.0（RAG）: RAG（Retrieval-Augmented Generation）技术可以被视为一种“人工稀释”。通过 RAG，我们将用户的 Prompt 与外部知识库的信息融合，人为地增加了模型的输入信息量，从而“稀释”了原始 Prompt 的直接影响。这种“稀释”是人为可控的，我们可以选择知识库、调整检索策略来控制“稀释”的程度和方向。</p>
</li>
<li>
<p>模型稀释 1.0（Thinking 模型）: Thinking 模型则代表了一种“模型自身驱动的稀释”。这类模型在推理过程中会产生大量的中间步骤和思考过程，这些“思考”虽然提升了模型的整体性能，但也进一步“稀释”了用户原始指令的权重。这种“稀释”是模型自身能力提升的体现，但也更难以直接控制。</p>
</li>
</ul>
<p>三、 “幻觉”的本质： “稀释”与“对齐”的失衡</p>
<p>长期以来，LLM 的“幻觉”（Hallucination）问题一直困扰着业界。但如果我们从“稀释效应”的角度来看待“幻觉”，或许可以得到更深刻的理解。</p>
<p>“幻觉”并非 LLM 凭空捏造了不存在的事实，而是模型在多维度“指令”和自身推理的复杂作用下，产生的与人类认知或期望不符的输出。这更像是一种“对齐”问题，而非简单的“错误”。</p>
<p>“幻觉”往往源于：</p>
<ul>
<li>潜台词和暗上下文: 用户 Prompt 中未明确表达的意图、隐含的假设、以及相关的背景知识，都可能成为模型“脑补”的素材，这可以视为一种“隐性稀释”。</li>
<li>过强的指令遵循: 当模型过分“听话”，试图从有限的输入中推断出过多信息时，也容易产生“幻觉”。</li>
<li>“稀释”过度: 当模型自身的推理和预训练知识过度主导输出结果时，“幻觉”就更容易出现。</li>
</ul>
<p>与其将“幻觉”视为“错误”并试图“纠正”，不如将其视为“稀释”的极端表现，通过工程化手段来 “引导和参与”“稀释” 的过程，实现模型输出与人类期望的“对齐”。</p>
<p>四、 企业级应用：驾驭“稀释”，实现人机协同</p>
<p>对于企业级 LLM 应用而言，理解和驾驭“稀释效应”至关重要。企业既希望 LLM 能够充分利用其强大的推理能力，产生更智能、更深入的洞察，又希望 LLM 的输出能够符合企业的特定需求、风格和规范。</p>
<p>这就需要我们 <strong>不仅仅是“控制”稀释，更是“引导”和“参与”稀释</strong>：</p>
<ul>
<li>Prompt 工程: 通过精心设计的 Prompt，明确用户意图，引导模型进行“有方向的稀释”。</li>
<li>RAG: 利用 RAG 技术，引入与企业相关的知识库，进行“可控的稀释”，为模型提供更精准的上下文。</li>
<li>Workflow 编排: 通过 Workflow 工具，将复杂的任务分解为多个步骤，并在每个步骤中对“稀释”进行精细化控制。</li>
<li>模型微调: 针对特定任务或领域，对模型进行微调，使其“稀释”的方向更符合企业需求。</li>
</ul>
<p>作为 LLM 平台提供商，我们致力于为企业提供构建、管理和优化 LLM 应用的工具和环境。我们的平台提供：</p>
<ul>
<li>灵活的 Prompt 工程工具: 帮助企业构建更精准、更有效的 Prompt，更好地引导 LLM 的行为。</li>
<li>强大的 RAG 集成能力: 允许企业将 LLM 与内部知识库无缝对接，为 LLM 提供更丰富、更可靠的上下文信息，实现“可控稀释”。</li>
<li>多样化的 Workflow 编排选项: 支持企业根据不同的业务场景，灵活定制 LLM 的工作流程，实现对“稀释”过程的精细化控制和引导。</li>
<li>深度定制和优化服务: 为有特殊需求的企业提供专业的咨询和技术支持，帮助企业构建高度定制化的 LLM 应用。</li>
</ul>
<p>我们相信，通过这些工具和服务，企业可以更好地驾驭 LLM，充分利用“稀释效应”的正面作用，实现 LLM 与人类的深度协同，共同创造更大的价值。</p>
<p>五、 总结与展望</p>
<p>LLM 的“指令遵循”并非简单的“是”或“否”的问题，而是一个涉及多维度“指令”交互、以及“稀释效应”影响的复杂过程。理解“稀释”，驾驭“稀释”，是释放 LLM 潜力的关键。</p>
<p>“稀释”并非 LLM 的缺陷，而是其强大推理能力的体现。关键在于如何通过工程化手段，让人类更好地“参与”到“稀释”过程中，实现 LLM 输出与人类期望的“对齐”，最终实现人机协同。</p>
<p>(由 Gemini 2.0 Pro, Flash-Thinking, Claude 3 Opus, 我 共同完成)</p>
<hr />
<h2>初稿</h2>
<p>模型的 “指令遵循” 和 结果效果是个很有意思的话题。</p>
<p>举例更好说明一些：</p>
<p>Claude.ai 和 ChatGPT.com 听用户 七到九分（满分 10），听 Anthropic/OpenAI 的 五到八分。</p>
<p>那么就会出现情况：7 分听用户的， 但是 8 分听了 OpenAI 的 - Prompt 和 工具 和里面（训练时）提供的各种 best practice（Eg. 今天起，ChatGPT 搜索人人可用，OpenAI 疯狂砸钱，雇 300+博士为 AI 打工-36 氪) 。</p>
<p>中学生问的题，博士可不一定按他想象地给答案和过程。</p>
<p>而另一个指令遵循是 9 分听用户，五六分听自己的，那么模型就很容易被 jailbreak。</p>
<p>我理解的 DeepSeek 和其他 推理模型的一个核心在于，后者（prompt/训练集/best practice/后训练）的内容无所谓，有高有低。
但前面 “听用户的” 部分，比如还是 9 分，但是推理部分也在 prompt 里，它稀释了原始用户。那么构成就是：</p>
<p>用户 9 + 模型和供应商本身的意愿 5 ➡️ 纯用户 6 + （推理部分 3 + model 5）。</p>
<p>那么稀释后的用户端指令遵循就只有 42%，低于 50%
（顺便，小模型可能总分低于 5 啥的。）
这就导致了推理模型的上下限都比大模型更大。</p>
<p>开发者是另一个情况。各路 playground 比如 Google ai studio 普遍允许修改 prompt 说过的话。注意力架构是高度依赖上下文的，那么这样就是 hack 了 “模型和供应商本身的意愿” 这部分，通过修改上下文 - 模型相信自己（but hacked）。</p>
<p>Prompt 是更温和的修改，hack 过于激进且难以复现和投产。（但或许有办法解决？）</p>
<p>模型商在预训练或者微调时提供 best practice，而企业用户通常通过 prompt - rag 技术等。</p>
<p>那么，或许模型等指令遵从能力，有表现形态，以及遵循谁的问题。</p>
<p>Deep Research 听 OpenAI 搭建的高质量素材，以及 prompt 进去的高质量论文，其次才是用户（某种角度上说）（我在自己的笔记有记录另一个思考，简单来说是事件的实现是三部分：意识意义愿景-&gt;意愿意志决策-&gt;推理计算运行）。
那么，我认为企业肯定也会需要 Deep Research，但是 prompt 进去的可能是内部文件和风格品牌。
模型既吃企业画的饼（意识层），也吃成员投入的燃料（意愿层）。</p>
<p>推理模型的一个特点是稀释。
另一个角度解读是，理想状态下，它仍然遵循人的 query - 在愿景 意识层；
至于决策 也就是意愿层，它会听自己的而不完全是用户给的，并 best practice 可能比一般人做得更好。</p>
<p>那么指令遵循当然还是遵循，只是用户画的饼它听，博士和全人类给的参考答案 推理过程 和计算器 numpy 的结果 它也听。</p>
<p>遵守 - 带来可用性，以及推理模型 - 带来能力的增强。</p>
<p>这是一个敲敲打打的工程学，可能并非科学甚至原理数学层面的突破。
当然，有一个过硬的基座模型是必要的。Anthropic 也这样说过，预训练是可通关的，很多厂商也阶段性地做到了。</p>
<p>推理模型类似全自动 agent，目前高度不可控。
接下来的话，prompt 够用吗？或者提供 rag 够用吗？workflow 够用吗？需不需要，以及如何介入推理环节？
企业的需求是什么，会为什么买账（在后 reasoning 和 后 agent 时代）？</p>
<hr />
<p>高质量愿景是稀缺的，高质量决策可以由 贵的好的 llm providers 提供。
那么一般员工做的，无非就是 搬运愿景，偶尔修改 - 添加随机性，将愿景（意识层）翻译为决策（意愿层）和行动。
超级个体在 LLM 带来的新时代，个体们会如何实现那三层？或者说超级个体的定义是什么，祂会什么样的形态存在？</p>
<h2>预告</h2>
<p>meta-dynamic 关于“三层”</p>
<h2>metadata</h2>
<blockquote>
<p>author: alterxyz (jerome @ dify.ai)
date: 2025年2月6日 初稿；2025年2月10日 正文</p>
</blockquote>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/7"/><published>2025-06-26T07:57:14+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/6</id><title>关于 memory 的重要性</title><updated>2025-06-26T08:27:43.802918+00:00</updated><content type="html"><![CDATA[<p>一个稳定可靠，或者至少自洽的记忆是至关重要的。如此才能构建一个自然的人格。
无论是人还是 AI。</p>
<p>很同意这会是个全面的工程。prompt engineering 之前很多人只是狭义的讨论 提示词么？那么重命名为 context engineering 也算是一种 refreshing 了挺好的。就像 agent 有点被炒作炒烂了，于是 agentic 这个词就又悄然成了共识。</p>
<p>例如, multi-agent 一步到位解决了连现实也难以完美解决的协作和管理是不显示的, 这是社会学和政治范畴. 但是, 通过 sub AI worker 和 各种工具来过滤噪音却还是能显著提高效果的.</p>
<p>详见 <strong>稀释</strong> <a href="https://github.com/alterxyz/gitblog/issues/7">GitHub</a> | <a href="https://alterxyz.github.io/gitblog/issue-7/">GitBlog</a> 这篇我的文章.</p>
<p>以及现阶段一个优异的实现是 <a href="https://github.com/SWE-agent/SWE-agent">SWE-agent</a>, 详见本文第二个 Deep Research.</p>
<hr />
<details>
  <summary>塑造 AI 思维：从提示到上下文工程的战略转移 (Gemini Deep Research - 仅供参考)</summary>
<h1><strong>塑造 AI 思维：从提示到上下文工程的战略转移</strong></h1>
<p><strong>执行摘要</strong></p>
<p>本报告旨在深入剖析人工智能应用开发领域的一项根本性转变：从“提示工程”（Prompt Engineering）到“上下文工程”（Context Engineering）的演进。这一转变并非简单的术语更迭，而是标志着行业从关注局部文本优化的“技艺”阶段，迈向了构建整体信息生态系统的“工程”纪元。Andrej Karpathy 等行业思想领袖的论述，为这一业已存在的实践赋予了明确的名称，从而加速了其理论化和体系化进程。</p>
<p>上下文工程的核心在于，它不再局限于雕琢单个输入指令，而是致力于设计和构建一个完整的、动态的信息环境。这个环境囊括了数据管道、检索机制、交互历史、可用工具以及领域知识，其最终目的是为了赋能大型语言模型（LLM）以一种可靠、可扩展且可预测的方式，完成复杂的、多步骤的真实世界任务。</p>
<p>本报告将系统性地阐述此范式转移。首先，我们将明确界定提示工程与上下文工程的范畴与区别，确立后者作为一种更宏大、更具系统性的工程学科的地位。其次，我们将深入技术层面，详细解析支撑上下文工程的核心架构，特别是以“检索增强生成”（Retrieval-Augmented Generation, RAG）为代表的技术栈及其高级实现。随后，报告将通过分析 DoorDash、LinkedIn 及 Perplexity AI 等前沿企业的真实案例，展示上下文工程在商业实践中的具体应用与巨大价值。最后，我们将探讨这一转变对 AI 开发者角色、技能需求及企业数据战略的深远影响，并为技术从业者与领导者提供前瞻性的战略展望与行动建议。</p>
<hr />
<h2><strong>第一部分：语义的演进：从雕琢词句到构建世界</strong></h2>
<p>人工智能应用开发领域正经历一场深刻的认知升级，其核心在于我们将如何与大型语言模型（LLM）协作。这场变革的焦点，正从如何“提问”的技艺，转向如何为其构建一个完整“世界观”的工程学科。著名 AI 科学家 Andrej Karpathy 的观点成为了这场讨论的催化剂，他主张使用“上下文工程”这一术语，因为它更精确地捕捉了当前 AI 开发的核心挑战，标志着该领域向着更成熟、更体系化的方向发展。</p>
<h3><strong>1.1 Karpathy 的催化作用：为新前沿命名</strong></h3>
<p>当 Andrej Karpathy 提出应更多地讨论“上下文工程”而非“提示工程”时，他并非发明了一个全新的概念，而是为一种已在顶尖开发者实践中普遍存在的趋势进行了精准命名 1。这一举动意义重大，因为它正式宣告了 AI 开发正在走出“凭感觉编程”（vibe coding）的早期探索阶段——一个开发者们更多是在实验和感受 AI 工具能力的时期 3。</p>
<p>开发者社区的积极反响证实了这一命名的时效性。许多工程师表示，他们早已在实践中朝着这个方向努力，但一直缺少一个恰当的词汇来概括这种系统性的工作 1。Karpathy 的提法，恰如其分地将零散的实践经验凝聚成一个清晰的学科方向，推动了行业共识的形成。它强调，决定高级 AI 应用成败的关键，已不再是那灵光一现的“神奇提示词”，而是其背后那个精心构建、持续供给信息的系统。</p>
<h3><strong>1.2 概念界定：范围与维度的差异</strong></h3>
<p>为了“正本清源”，必须精确地区分提示工程与上下文工程。二者的根本差异在于其工作范围、目标和所处的抽象层次。</p>
<ul>
<li><strong>提示工程（Prompt Engineering）</strong>：可以被狭义地定义为一种<strong>技艺</strong>，其核心目标是<strong>优化文本输入</strong>。它专注于通过精心选择和组织词语、短语、句子结构乃至标点符号，来引导 LLM 在<strong>单次或有限次的交互</strong>中生成最符合预期的、高质量的输出 6。其本质是追求与模型进行清晰、高效的沟通，好比一位管理者向员工下达明确无误的工作指令 9。它的作用域是用户与模型之间的那个“提示词”本身。  </li>
<li><strong>上下文工程（Context Engineering）</strong>：则是一门<strong>工程学科</strong>，其核心目标是<strong>设计和构建动态的、可扩展的系统</strong>。这个系统负责为 LLM 提供完成复杂任务所需的一切元素：正确的信息、可用的工具、相关的历史对话、明确的指令以及领域知识，并确保这些元素以正确的格式被动态地组织和利用 9。它关注的不是单次交互，而是整个<br />
<strong>信息生态系统</strong>的构建与维护，这个生态系统将支撑 AI 在连续的、多步骤的流程中可靠地运行 6。</li>
</ul>
<p>由此可见，<strong>提示工程是上下文工程的一个子集</strong> 9。这个观点至关重要。如果将构建一个 AI 应用比作烹饪，那么提示工程就像是撰写一份清晰的菜谱（recipe），而上下文工程则是设计整座厨房（kitchen）：包括决定食材的采购渠道与标准（数据源与质量）、设计食材处理流水线（数据管道）、配置厨具（工具集），并教会厨师（LLM）如何理解菜谱、使用厨具以及记住顾客的口味偏好（交互历史与个性化）12。</p>
<h3><strong>1.3 为何需要这种转变：从局部优化到系统可靠性</strong></h3>
<p>在真实的生产环境中，单纯依赖提示工程的局限性显而易见。一个措辞再完美的提示，也无法弥补上下文信息的缺失或错误 14。开发者们发现，为了让 AI 应用在面对各种边缘情况时依然能保持稳定和一致，他们花费在准备和构建上下文上的时间，远超调整提示词本身 14。</p>
<p>这种转变的根本原因在于，它触及了 LLM 应用失败的核心症结。大多数情况下，模型表现不佳并非源于其“智力”不足，而是因为它没有获得做出正确判断所必需的信息 11。上下文工程将开发的重心从优化那个最终提交给模型的、静态的“提示字符串”，转移到了动态地管理和填充整个“上下文窗口”（Context Window）——这个模型在进行推理时能够看到的所有信息的总和。</p>
<p>这种从“技艺”到“工程”的语义演进，其背后是行业专业化和成熟化的必然趋势。将这一核心工作冠以“工程”之名，本身就是一种战略性的举措。它摒弃了“提示工程”一词常带有的、类似“炼金术”或“黑客技巧”的临时性和不可捉摸感 10，而引入了系统化、可重复、可度量、可维护的工程学内涵 14。这使得 AI 应用的开发过程能够与成熟的软件开发生命周期（SDLC）和 DevOps 理念相结合 15，从而更容易被企业级应用所接纳和投资。企业愿意为有明确投资回报率的工程学科投入资源，而非模糊的“手艺”。因此，将“上下文”提升到工程的高度，是推动生成式 AI 从有趣的玩具转变为可靠的生产力工具的关键一步。</p>
<p><strong>表 1：提示工程 vs. 上下文工程：核心差异对比</strong></p>
<table>
<thead>
<tr>
<th align="left">特征</th>
<th align="left">提示工程 (Prompt Engineering)</th>
<th align="left">上下文工程 (Context Engineering)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>核心目标</strong></td>
<td align="left">引导模型生成特定的、高质量的单次响应。</td>
<td align="left">构建一个能支持模型持续、可靠执行复杂任务的系统。</td>
</tr>
<tr>
<td align="left"><strong>工作范畴</strong></td>
<td align="left">用户输入的指令字符串（Prompt）。</td>
<td align="left">整个信息环境，包括数据、工具、历史记录、外部知识库等。</td>
</tr>
<tr>
<td align="left"><strong>核心隐喻</strong></td>
<td align="left">撰写一份清晰明确的菜谱。</td>
<td align="left">设计、建造并运营整座自动化厨房。</td>
</tr>
<tr>
<td align="left"><strong>关键技能</strong></td>
<td align="left">语言表达、创意构思、指令清晰度、领域知识的文字化。</td>
<td align="left">系统设计、数据架构、信息检索、API 集成、流程编排。</td>
</tr>
<tr>
<td align="left"><strong>时间维度</strong></td>
<td align="left">关注单次交互或孤立的任务。</td>
<td align="left">关注连续的、多轮的、可能长期运行的交互流程。</td>
</tr>
<tr>
<td align="left"><strong>产出物</strong></td>
<td align="left">一个或一组精心设计的文本提示模板。</td>
<td align="left">一套完整的数据管道、检索系统、Agentic 框架或评估体系。</td>
</tr>
<tr>
<td align="left"><strong>关注点</strong></td>
<td align="left">“我应该<strong>如何问</strong>这个问题？”</td>
<td align="left">“为了让 AI 能回答这类问题，它需要<strong>知道什么</strong>？”</td>
</tr>
</tbody></table><hr />
<h2><strong>第二部分：上下文工程的架构基石</strong></h2>
<p>如果说上下文工程是构建智能应用的蓝图，那么其实现则依赖于一套坚实的、以数据为中心的架构。这一架构的核心思想是，不再仅仅依赖 LLM 内部固化的、可能过时的知识，而是通过动态地、实时地为其注入外部世界的信息来增强其能力。本节将深入剖析支撑上下文工程的技术体系，从核心引擎 RAG 到更为复杂的生产级实现。</p>
<h3><strong>2.1 检索增强生成 (RAG)：核心驱动引擎</strong></h3>
<p>检索增强生成（Retrieval-Augmented Generation, RAG）是上下文工程中最核心、最广为人知的技术框架 17。它通过将传统的信息检索系统（如搜索引擎和数据库）与 LLM 的强大生成能力相结合，从根本上解决了 LLM 的一些固有缺陷。</p>
<ul>
<li><strong>定义与目的</strong>：RAG 的核心目的在于，通过从外部权威知识库中检索相关信息，来“增强”LLM 的生成过程，从而使其回答更加准确、及时，并有事实依据 18。这极大地缓解了 LLM 的“幻觉”（Hallucination）问题，即模型在缺乏知识时凭空捏造事实的倾向 9。对于企业而言，RAG 的最大价值在于，它允许组织利用自己最新的、专有的内部数据来驱动 AI 应用，而无需承担重新训练或微调大型模型所带来的高昂计算和财务成本 19。  </li>
<li>
<strong>RAG 的标准工作流</strong>：一个典型的 RAG 系统通常包含以下几个关键步骤 21：  <ol>
<li><strong>数据注入与预处理 (Ingestion &amp; Preparation)</strong>：首先，系统需要接入外部数据源，这可以是公司的内部文档、数据库记录、API 接口，甚至是网页内容。这些原始数据经过清洗、格式转换等预处理步骤，形成一个可供 AI 理解的“知识库” 18。  </li>
<li><strong>嵌入与索引 (Embedding &amp; Indexing)</strong>：接下来，系统使用一种称为“嵌入模型”（Embedding Model）的 AI 技术，将预处理后的文本数据（通常被切分成小块，即“chunks”）转换成高维的数字向量（即“嵌入”）。这些向量能够捕捉文本的语义信息。随后，这些向量被存入一个专门的“向量数据库”中，并建立索引，以便进行快速的相似性搜索 21。  </li>
<li><strong>检索 (Retrieval)</strong>：当用户提出一个问题时，系统同样会将这个问题转换成一个查询向量。然后，利用这个查询向量在向量数据库中进行搜索，找出与问题语义最相似的若干个文本块（chunks）18。  </li>
<li><strong>增强与生成 (Augmentation &amp; Generation)</strong>：检索到的这些高相关性文本块，会连同用户的原始问题一起，被“塞”进（stuffing）一个最终的提示中，形成一个“增强提示”（Augmented Prompt）。这个提示被发送给 LLM。由于 LLM 此时获得了完成任务所需的精确上下文，它便能生成一个有事实依据的、高质量的回答 19。  </li>
<li><strong>数据生命周期管理 (Data Lifecycle)</strong>：为了保证信息的时效性，外部知识库必须能够被持续更新。这可以通过自动化的实时或批量处理流程来完成，确保 RAG 系统能够访问到最新的数据 21。</li>
</ol>
</li>
</ul>
<h3><strong>2.2 超越基础 RAG：面向生产环境的高级技术</strong></h3>
<p>虽然基础的 RAG 流程已经非常强大，但在复杂的生产环境中，为了应对查询的模糊性、上下文的细微差别以及对性能的极致要求，开发者们已经发展出了一系列高级技术 26。</p>
<ul>
<li>
<strong>高级检索策略</strong>：  <ul>
<li><strong>混合搜索 (Hybrid Search)</strong>：将捕捉语义相似性的向量搜索与捕捉精确匹配的传统关键词搜索相结合。这种方法在处理包含特定术语（如产品型号、专有名词、医疗术语）的查询时尤为有效，因为它兼顾了“意思相近”和“字面相同”两种情况 18。  </li>
<li><strong>重排序 (Re-ranking)</strong>：在检索到初步的文档列表后，使用一个计算更密集、能力更强的“重排序模型”（通常是交叉编码器 Cross-Encoder）对这个列表进行二次排序，以确保最相关的文档排在最前面。这相当于在将上下文交给昂贵的 LLM 之前，进行了一次精细的“提纯”，显著提高了信噪比 18。  </li>
<li><strong>查询转换 (Query Transformations)</strong>：在进行检索之前，先对用户的原始查询进行优化。常见技术包括：<strong>查询扩展</strong>（为查询补充同义词或相关术语）、<strong>查询分解</strong>（将一个复杂问题拆解成多个可以独立检索的子问题），以及<strong>后退提示</strong>（Step-back Prompting，即先生成一个更宽泛、更抽象的问题来获取宏观背景知识，再结合原始问题的细节进行精确检索）23。  </li>
</ul>
</li>
<li>
<strong>高级数据处理与分块</strong>：  <ul>
<li>如何将长文档切分成合适的“块”是 RAG 性能的关键。<strong>语义分块</strong>（Semantic Chunking）技术，即根据文本的语义连贯性而非固定的字符数来切分，能产生更具内在逻辑的文本块。此外，为<strong>句子的滑动窗口</strong>（sliding windows of sentences）创建嵌入，也能更好地保留句子间的上下文联系 23。  </li>
</ul>
</li>
<li>
<strong>GraphRAG：融合结构化知识</strong>：  <ul>
<li>对于需要多步推理的复杂问题（multi-hop questions），将知识以图谱（由实体和关系组成）的形式进行组织，其效果远胜于非结构化的纯文本。<strong>GraphRAG</strong> 技术通过从知识图谱中检索相关的子图，并将其中的结构化信息与传统的向量检索结果相结合，为 LLM 提供了更丰富、更具关联性的上下文 19。LinkedIn 将历史支持工单构建成知识图谱用于客服问答，便是一个成功的商业实例 16。</li>
</ul>
</li>
</ul>
<h3><strong>2.3 Agentic 架构与工具使用</strong></h3>
<p>上下文工程是构建高效 AI 代理（Agent）的基石。一个 AI 代理不仅仅是一个聊天机器人，它是一个能够进行推理、规划并使用外部工具来达成目标的智能系统 29。</p>
<ul>
<li><strong>函数调用 (Function Calling) 作为上下文工具</strong>：函数调用是 LLM 与外部世界（如 API、数据库、代码执行环境）交互的核心机制 32。在实践中，开发者会将一系列可用工具（以函数的形式）的描述作为上下文提供给 LLM。LLM 在理解用户意图后，能够自行判断是否需要以及何时调用某个工具，并以结构化格式（通常是 JSON）生成调用该函数所需的参数 32。这是实现 Agentic RAG 的关键一环，使得 AI 代理能从一个被动的信息整合者，转变为一个主动的任务执行者 30。  </li>
<li>
<strong>单代理 vs. 多代理架构之辩</strong>：  <ul>
<li>一个流行的构想是构建一个由多个专职代理组成的“团队”，让它们协作完成复杂任务。然而，目前的行业实践表明，这种多代理架构往往非常脆弱 11。其根本原因在于，在多个代理之间高效、无损地共享和同步上下文是一个巨大的技术挑战。缺乏共享的上下文会导致决策冲突和工作成果的不连贯 11。  </li>
<li>相比之下，一种更稳健、更可靠的架构是<strong>单线程线性代理</strong>（single-threaded linear agent）。在这种架构中，上下文在任务的每一步中都是连续且共享的，从而避免了因代理间沟通不畅而导致的“滚雪球式”的错误累积 11。这一争论凸显了，上下文流的管理已经成为 AI 应用架构设计的首要考量。</li>
</ul>
</li>
</ul>
<p>在深入探讨这些技术时，一个关键的认知浮出水面：<strong>上下文工程本质上是 AI 时代的数据工程</strong>。整个 RAG 及其高级变体的流水线——从数据抽取、转换、加载（ETL），到数据建模（嵌入）、存储（向量数据库）和查询（检索）——都与传统数据工程的核心任务一一对应 21。企业在实施上下文工程时遇到的最大挑战，如数据质量低下、信息孤岛、治理缺失等 12，也正是数据工程领域长期致力于解决的经典难题 36。这意味着，拥有成熟数据工程文化和实践的组织，在迈向高级 AI 应用的道路上将拥有显著的先发优势。</p>
<p>同时，另一个重要的观点是，<strong>不断增大的“上下文窗口”并非 RAG 的替代品，反而使其变得更为重要</strong>。尽管像 Claude 3 提供的 200k token 上下文窗口看似能让开发者“一股脑”地塞入大量信息 37，但实践和研究均表明，模型在处理超长上下文时存在“迷失在中间”（lost in the middle）的问题，即对输入序列中部信息的注意力会显著下降 15。此外，处理长上下文也意味着更高的 API 调用成本和更长的响应延迟 14。因此，RAG 扮演了一个至关重要的“智能预处理器”角色。与其将海量无关信息全部填入昂贵的上下文窗口，远不如先用廉价高效的检索技术，从海量文档中精确定位出最相关的几个段落。RAG 与大上下文窗口是互补的：RAG 负责决定</p>
<p><strong>什么</strong>信息值得被放入宝贵的上下文窗口中。</p>
<p><strong>表 2：生产级 RAG 系统的关键组件</strong></p>
<table>
<thead>
<tr>
<th align="left">组件</th>
<th align="left">目的</th>
<th align="left">关键技术/工具</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>数据注入 (Data Ingestion)</strong></td>
<td align="left">从不同来源获取并准备外部知识。</td>
<td align="left">API 连接器、数据库连接器、网络爬虫、ETL 脚本。</td>
</tr>
<tr>
<td align="left"><strong>分块策略 (Chunking Strategy)</strong></td>
<td align="left">将文档分解为大小适中且语义连贯的信息块。</td>
<td align="left">语义分块、句子滑动窗口、基于命题的分块 (Proposition-based chunking)。</td>
</tr>
<tr>
<td align="left"><strong>嵌入模型 (Embedding Model)</strong></td>
<td align="left">将文本块转换为能够捕捉语义的向量。</td>
<td align="left">Sentence-Transformers, OpenAI Embeddings, Cohere Embeddings, 多模态模型。</td>
</tr>
<tr>
<td align="left"><strong>向量存储 (Vector Store)</strong></td>
<td align="left">高效地存储、索引和查询海量向量。</td>
<td align="left">向量数据库 (如 Pinecone, Weaviate, Milvus), Vertex AI Search, Elasticsearch。</td>
</tr>
<tr>
<td align="left"><strong>检索逻辑 (Retrieval Logic)</strong></td>
<td align="left">根据用户查询，找出最相关的上下文信息。</td>
<td align="left">向量搜索、关键词搜索、混合搜索、查询转换 (如 HyDE)。</td>
</tr>
<tr>
<td align="left"><strong>重排序模型 (Re-ranking Model)</strong></td>
<td align="left">对初步检索结果进行二次精排，提升相关性。</td>
<td align="left">交叉编码器 (Cross-Encoders)、基于 LLM 的评估 (LLM-as-a-judge)。</td>
</tr>
<tr>
<td align="left"><strong>生成模型 (Generator LLM)</strong></td>
<td align="left">基于增强后的提示，综合信息并生成最终答案。</td>
<td align="left">GPT-4, Claude 3, Llama 3, Gemini 1.5 Pro。</td>
</tr>
<tr>
<td align="left"><strong>评估与护栏 (Evaluation &amp; Guardrails)</strong></td>
<td align="left">监控系统性能，确保输出的准确性、安全性与合规性。</td>
<td align="left">LLM-as-a-judge 框架、事实核查管道、输出格式与内容验证。</td>
</tr>
</tbody></table><hr />
<h2><strong>第三部分：上下文工程的实践：案例研究与范例剖析</strong></h2>
<p>理论的价值最终体现在实践中。本节将从抽象的架构讨论转向具体的商业应用，通过剖析行业领先企业的案例，展示上下文工程的原则如何转化为可衡量的商业价值和卓越的用户体验。这些案例揭示了一个共同的趋势：竞争优势正从模型本身转向围绕模型构建的、独特的、高效的上下文生态系统。</p>
<h3><strong>3.1 企业应用：构建由上下文驱动的商业解决方案</strong></h3>
<p>大型企业正在积极利用 RAG 和上下文管理来解决其核心业务中的高价值问题，通过将专有数据转化为 AI 的即时知识，实现降本增效和体验提升。</p>
<ul>
<li>
<strong>案例研究：DoorDash —— 高质量的自动化支持</strong>  <ul>
<li><strong>业务挑战</strong>：为数量庞大的送餐员（“Dashers”）提供快速、准确、一致的自动化支持服务。  </li>
<li><strong>解决方案</strong>：DoorDash 构建了一个复杂的、多组件的 RAG 系统。其核心不仅在于从帮助文档和历史案例中检索信息，更在于其完善的质量控制体系。该体系包括：1) 一个核心的 <strong>RAG 系统</strong>，用于信息检索；2) 一个 <strong>“LLM 护栏”</strong>（LLM Guardrail），实时监控生成内容，确保其准确性并符合公司政策；3) 一个 <strong>“LLM 评判官”</strong>（LLM Judge），用于持续评估系统在相关性、连贯性等多个维度上的表现 16。  </li>
<li><strong>实践启示</strong>：此案例雄辩地证明，一个生产级的上下文工程应用，远不止“检索+生成”这么简单。它是一个包含<strong>检索、生成、评估和监控</strong>的完整闭环生态系统。对质量的持续度量和控制是其成功的关键。  </li>
</ul>
</li>
<li>
<strong>案例研究：LinkedIn —— 用于客户服务的结构化上下文</strong>  <ul>
<li><strong>业务挑战</strong>：面对海量的历史客户服务工单，如何高效地为新的用户问题找到解决方案。  </li>
<li><strong>解决方案</strong>：LinkedIn 认识到，将历史工单视为独立的纯文本文件会丢失大量有价值的关联信息。因此，他们采取了更高级的策略：将这些工单数据构建成一个<strong>知识图谱</strong>（Knowledge Graph），明确地表示出不同问题、解决方案和用户之间的内在联系。其 RAG 系统在响应查询时，会从这个图谱中检索相关的<strong>子图</strong>作为上下文，而不仅仅是文本片段 16。  </li>
<li><strong>量化成果</strong>：这一基于结构化上下文的先进方法，使得 LinkedIn 客服团队的<strong>平均问题解决时间中位数降低了 28.6%</strong> 16。  </li>
<li><strong>实践启示</strong>：在处理具有复杂内部关联的数据域时（如客服、法规、供应链），GraphRAG 等利用结构化上下文的技术，相比简单的文本检索具有压倒性的优势。上下文的“结构”本身就是一种宝贵的信息。  </li>
</ul>
</li>
<li>
<strong>案例研究：Bell —— 可扩展的知识管理</strong>  <ul>
<li><strong>业务挑战</strong>：确保公司员工能够随时访问到最新、最准确的内部政策和流程文档。  </li>
<li><strong>解决方案</strong>：加拿大电信巨头 Bell 公司部署了一套模块化的 RAG 系统。该系统的特点在于其强大的数据注入管道，能够支持对知识库的批量和增量更新，并采用<strong>DevOps 原则</strong>来管理和维护整个系统，将其视为一个标准的软件服务来对待 16。  </li>
<li><strong>实践启示</strong>：此案例强调了上下文<strong>生命周期管理</strong>的重要性。上下文不是一次性的构建，而是一个需要持续维护、更新和迭代的动态资产。将其纳入成熟的软件工程管理流程是保证其长期价值的前提。</li>
</ul>
</li>
</ul>
<h3><strong>3.2 “答案引擎”范式：Perplexity AI 深度剖析</strong></h3>
<p>如果说上述案例展示了上下文工程在企业内部的应用，那么 Perplexity AI 则完美诠释了如何将这些原则应用于一个面向公众的、革命性的产品。它不是传统的搜索引擎，也不是简单的聊天机器人，而是一个被业界称为“答案引擎”（Answer Engine）的新物种，是上下文工程理念的集大成者。</p>
<ul>
<li><strong>核心功能</strong>：Perplexity 的工作模式是 RAG 在全网范围内的宏大应用。它接收用户的自然语言问题，通过<strong>实时网络搜索</strong>来收集信息，然后利用 LLM 将检索到的信息综合、提炼成一个直接、连贯、有来源引用的回答，而非仅仅罗列一堆链接 39。  </li>
<li>
<strong>Perplexity AI 中的上下文工程实践</strong>：  <ul>
<li><strong>实时检索作为上下文</strong>：与依赖静态训练数据的 LLM 不同，Perplexity 的核心竞争力在于其为每个问题动态构建上下文的能力。它会实时访问网络，确保提供给 LLM 的信息是最新鲜的 40。  </li>
<li><strong>对话记忆与上下文保持</strong>：Perplexity 通过“线程”（Threads）的概念来管理对话历史。在同一个线程中，用户可以不断追问，而模型会记住之前的对话内容，无需用户重复提供背景信息。这是一种高效的会话级上下文管理机制 39。  </li>
<li><strong>来源追溯与事实接地</strong>：这是 RAG 的标志性优势。Perplexity 生成的每一个关键信息点都会附上来源引用，用户可以轻松点击链接，核实原始出处。这极大地增强了答案的可信度，是建立用户信任的关键 39。  </li>
<li><strong>用户自定义上下文</strong>：平台允许用户上传自己的文档（如 PDF）或图片，将其作为私有知识源纳入到当次查询的上下文中 42。其 API 甚至提供了<br />
search_context_size 这样的参数，让开发者可以根据成本和性能需求，精细地控制从网络检索的上下文数量 38。  </li>
<li><strong>基于上下文的查询理解</strong>：Perplexity 不仅检索上下文，还利用 LLM 来深刻理解用户的查询意图，超越了简单的关键词匹配。其“专业搜索”（Pro Search）模式甚至会主动向用户提出澄清性问题，以进一步精确化上下文的构建 39。</li>
</ul>
</li>
</ul>
<p>这些案例共同揭示了一个深刻的行业趋势：AI 应用的价值核心正在发生转移。随着强大的基础模型日益商品化，通过 API 即可轻松调用，拥有一个略胜一筹的模型本身已不再构成坚固的护城河。真正的、可持续的竞争优势，来源于企业所拥有的独特的、专有的数据，以及更重要的——将这些数据高效、可靠地<strong>工程化为 AI 可用上下文</strong>的能力。DoorDash 的护城河是其精细的知识库和评估体系，LinkedIn 的护城河是其结构化的工单知识图谱，Perplexity 的护城河是其大规模实时编排网络信息为上下文的能力。未来，AI 领域的竞争将不再是“模型之战”，而是“上下文之战”。</p>
<hr />
<h2><strong>第四部分：人的因素：重新定义 AI 开发者的角色与技能</strong></h2>
<p>从提示工程到上下文工程的范式转移，不仅仅是技术栈的更新，更深刻地重塑了 AI 开发者的角色定位、技能要求以及团队协作模式。当 AI 从一个需要被巧妙“哄骗”的黑箱，变成一个需要被系统性“赋能”的合作伙伴时，对其进行“工程化”的人，其价值和职责也必然随之演变。</p>
<h3><strong>4.1 从提示词工匠到系统架构师：角色的演进</strong></h3>
<p>开发者的工作重心正在从“局部”转向“全局”。过去，人们津津乐道的是如何通过遣词造句的“微操”来获得惊艳的单次输出；而现在，真正的挑战在于如何设计一个稳健的系统，使其在面对成千上万次不同的输入时，依然能保持高质量和高可靠性。</p>
<p>这种转变意味着，AI 开发者的角色正在从一个<strong>提示词工匠</strong>（Prompt Crafter）演变为一个<strong>系统架构师</strong>（Systems Architect）3。最有价值的工程师，不再是那个能写出最精妙提示或最多代码的人，而是那个能够最清晰地向 AI 系统</p>
<p><strong>阐明项目需求、架构约束和领域规则</strong>的人。这种能力，被一些从业者称为“上下文阐明”（Context Articulation），已成为新的核心竞争力 29。在这个新范式下，开发者更像是一位集导演、编剧和舞台监督于一身的创作者，负责为 AI 这个“演员”准备好它登台所需的一切：剧本（任务目标）、场景（数据环境）、道具（工具集）和与其他演员的互动规则（协作流程）3。或者，用另一个比喻来说，人类专家是提供方向和智慧的“蜂后”，而 AI 是勤奋执行的“工蜂”，上下文工程则是连接二者、使其高效协作的“蜂巢”架构 44。</p>
<h3><strong>4.2 上下文工程师的新兴技能栈</strong></h3>
<p>要胜任这一新角色，开发者需要一套融合了传统软件工程、数据工程和对 AI 深刻理解的复合型技能。</p>
<ul>
<li>
<strong>核心技术能力</strong>：  <ul>
<li><strong>数据管道与 ETL</strong>：由于上下文工程的核心是为 LLM 准备数据，因此，熟练构建和管理从各种数据源（API、数据库、文档库）抽取、转换和加载数据的管道，成为了基础中的基础。  </li>
<li><strong>信息检索与搜索技术</strong>：必须深入理解向量数据库的原理、嵌入模型的选择与使用，并掌握混合搜索、重排序等高级检索策略，以确保检索到的上下文既相关又精确。  </li>
<li><strong>系统设计与 Agentic 框架</strong>：需要具备设计可扩展、高可用的分布式系统的能力，特别是涉及 Agentic 框架和函数调用（Tool Use）的复杂系统。这要求开发者思考状态管理、任务编排和错误处理等问题。  </li>
<li><strong>评估、测试与可观测性</strong>：这是从“手艺”迈向“工程”的关键。开发者需要为 RAG 系统的输出质量（如相关性、事实一致性）建立量化评估体系，并将提示词和上下文配置视为代码的一部分，对其进行版本控制、单元测试和持续集成 14。  </li>
</ul>
</li>
<li>
<strong>战略与软性技能</strong>：  <ul>
<li><strong>上下文阐明 (Context Articulation)</strong>：如前所述，这是将模糊的业务需求和复杂的领域知识，转化为 AI 能够理解和执行的结构化上下文的能力 29。  </li>
<li><strong>问题建模 (Problem Formulation)</strong>：成功的关键往往在于对问题本身的深刻定义，而非对提示词的反复修改。开发者需要将重心前移，与业务方一起明确问题的范围、边界和成功标准 7。  </li>
<li><strong>跨职能协作</strong>：上下文工程绝非一人之功，它是一项“团队运动”。它要求 AI 开发者与数据工程师、领域专家、产品经理甚至法务与合规团队紧密合作，才能构建出完整、准确的上下文视图 12。</li>
</ul>
</li>
</ul>
<h3><strong>4.3 企业的挑战：驯服碎片化的知识</strong></h3>
<p>对于大型组织而言，实施上下文工程的最大障碍，往往不是技术选型，而是其内部知识管理的现状，即“上下文的混乱”（Context Chaos）12。</p>
<ul>
<li><strong>问题的根源</strong>：企业的关键知识资产通常是<strong>碎片化</strong>的，散落在数十个不同的系统里（如 Jira、Confluence、SharePoint、Slack、CRM 等）；这些知识往往是<strong>不一致</strong>的，同一个概念（如“活跃用户”）在不同部门有不同的定义；它们是<strong>不可信</strong>的，充满了过时信息、手动覆盖和重复逻辑；并且<strong>缺乏明确的所有权</strong>，当 AI 需要一个权威解释时，无人能提供最终答案 12。  </li>
<li>
<strong>解决方案：一种社会技术工程</strong>：解决这个问题，需要超越纯粹的技术视角，将其视为一个社会技术系统工程。这要求企业采取一套组合拳：  <ol>
<li><strong>绘制上下文地图</strong>：首先，需要系统性地盘点和梳理组织内最关键的知识资产，识别其位置、依赖关系和质量状况。  </li>
<li><strong>建立治理体系</strong>：为关键的上下文数据明确所有者、制定标准和访问策略，将其作为一种受管理的核心资产来对待。  </li>
<li><strong>先联邦，后整合</strong>：不要试图一蹴而就地建立一个完美的、集中的“上下文中心”。更务实的做法是，先通过技术手段实现对现有分散系统的<strong>联邦式访问</strong>，然后根据业务价值，逐步将最核心、最通用的上下文层（如核心业务指标定义、组织架构、产品分类等）进行整合 12。</li>
</ol>
</li>
</ul>
<p>这一系列挑战和应对策略，催生了一个关键角色的复兴和升级：<strong>知识工程师 (Knowledge Engineer)</strong>。在上下文工程的时代，知识工程师的角色变得至关重要。他们是连接业务、数据和 AI 的桥梁，其核心职责不再是为传统的专家系统构建规则，而是系统性地捕获、建模、组织和治理企业的知识，最终将其转化为 AI 可以消费的、高质量的上下文 36。他们需要深入理解数据的“5W1H”（Who, What, Where, When, Why, How）36，并利用知识图谱等技术，为企业构建一个可信的、可供 AI 查询的“数字孪生大脑”。这个角色的崛起，标志着企业对“上下文”这一无形资产的战略重视已提升到新的高度。</p>
<p><strong>表 3：AI 应用开发者技能演进趋势</strong></p>
<table>
<thead>
<tr>
<th align="left">技能类别</th>
<th align="left">相对重要性下降 (或成为基础门槛)</th>
<th align="left">相对重要性上升 (新前沿)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>模型交互</strong></td>
<td align="left">手工雕琢单个提示词、探索“越狱”技巧。</td>
<td align="left">系统化的提示模板管理、版本控制、自动化评估。</td>
</tr>
<tr>
<td align="left"><strong>数据处理</strong></td>
<td align="left">使用他人预处理好的数据集。</td>
<td align="left">构建稳健的数据注入、清洗、分块和更新管道。</td>
</tr>
<tr>
<td align="left"><strong>系统架构</strong></td>
<td align="left">开发简单的、单轮交互的应用。</td>
<td align="left">设计复杂的多步骤、多工具的 Agentic 系统。</td>
</tr>
<tr>
<td align="left"><strong>核心知识</strong></td>
<td align="left">掌握特定模型的“怪癖”和技巧。</td>
<td align="left">掌握信息检索、数据建模、系统设计等基本原理。</td>
</tr>
<tr>
<td align="left"><strong>团队协作</strong></td>
<td align="left">在开发团队内部协作。</td>
<td align="left">领导跨职能团队，与领域专家、数据、法务等部门协作。</td>
</tr>
</tbody></table><hr />
<h2><strong>第五部分：战略展望与建议</strong></h2>
<p>随着上下文工程从一个新兴概念迅速成为构建高级 AI 应用的行业标准，我们有必要站在一个更宏观的视角，审视其长远影响，并为身处其中的开发者和技术领导者提供战略性的指引。</p>
<h3><strong>5.1 未来是上下文感知的：为何上下文是新的竞争护城河</strong></h3>
<p>在可预见的未来，随着顶级的大型语言模型在能力上趋于同质化，并作为一种基础设施通过 API 广泛可用，竞争的焦点将发生决定性的转移。构建差异化和防御性壁垒的关键，将不再是拥有一个参数量更大或在某个基准上得分稍高的<strong>模型</strong>，而是企业所拥有的独特的、专有的<strong>数据</strong>，以及更重要的——将这些数据<strong>工程化为高质量上下文</strong>的能力 12。</p>
<p>AI 应用的质量上限，将不再由 LLM 的“智商”决定，而将由我们能为其提供的上下文的质量、新鲜度和相关性所决定。一句在开发者圈中广为流传的话精辟地总结了这一点：“上帝渴望上下文”（God is hungry for context）45。未来，那些能够最好地“喂养”AI 的组织，将释放出其最强大的生产力。上下文，而非模型本身，正在成为新的、最坚固的竞争护城河。</p>
<h3><strong>5.2 “上下文工程”只是一个新潮的术语吗？</strong></h3>
<p>面对任何一个新兴术语，一个合理的质疑是：它是否仅仅是对已有概念的重新包装？</p>
<p>对此，我们的分析认为，尽管上下文工程的许多底层原则确实借鉴了信息科学、知识管理、数据工程和认知系统工程等领域数十年的研究成果 36，但将其应用于大型语言模型这一独特的、概率性的、非结构化信息处理的新范式时，它催生出了一门真正独特的、综合性的新工程学科。</p>
<p>这个术语之所以有价值，因为它精准地捕捉到了当前阶段的核心挑战：如何系统性地将人类积累的、往往是混乱且隐性的知识，结构化地、动态地呈现给一个强大的、但不具备人类常识和真实世界经验的非人类智能体。它不是任何一个旧有学科的简单延伸，而是多个学科在一个全新问题域下的交叉、融合与升华。因此，“上下文工程”是一个有用且准确的描述符，它为这个新兴领域提供了清晰的身份认同和发展方向。</p>
<h3><strong>5.3 对开发者与技术领导者的建议</strong></h3>
<p>为了在上下文工程的时代保持领先，从业者和决策者需要主动调整其战略和行动。</p>
<ul>
<li>
<strong>对个人开发者的建议</strong>：  <ol>
<li><strong>像数据工程师一样思考</strong>：投入时间学习数据管道技术（如 Airflow, dbt）、数据建模和信息检索的核心原理。将自己视为一个为 AI 消费端构建数据产品的人。  </li>
<li><strong>拥抱系统思维</strong>：将视野从优化单个提示或函数，提升到设计整个信息流架构的高度。关注系统的可靠性、可观测性和可扩展性。  </li>
<li><strong>将上下文视为代码</strong>：为你构建的上下文管道（包括提示模板、RAG 配置等）引入严格的软件工程实践，包括版本控制（如 Git）、自动化测试和持续评估 15。  </li>
</ol>
</li>
<li>
<strong>对技术领导者的建议</strong>：  <ol>
<li><strong>投资“上下文层”</strong>：将数据治理和构建统一、可信的“上下文层”提升到企业核心战略的高度，而非仅仅是某个项目的技术实现细节。它是未来所有 AI 应用的基石。  </li>
<li><strong>重塑角色与团队</strong>：打破部门墙，积极组建由领域专家、数据工程师和 AI 开发者构成的跨职能“上下文团队”。认真考虑设立专门的“知识工程”职能，负责企业知识资产的梳理与管理 12。  </li>
<li><strong>以评估为导向</strong>：建立并投资于强大的评估框架，用以持续、量化地度量上下文驱动的 AI 系统的性能、准确性和商业价值。没有度量，就没有工程 14。</li>
</ol>
</li>
</ul>
<p>最终，上下文工程的成熟将引领我们走向一个“<strong>隐形提示</strong>”（Invisible Prompt）的未来。当一个 AI 系统能够通过其背后的、强大的上下文工程能力，自动感知用户所处的环境（例如，用户正在查看的屏幕、正在编辑的文档、其在组织中的角色），并主动预测其需求、检索所需信息时，用户与 AI 的交互将变得前所未有的自然和无缝。届时，用户可能只需说一句“这里情况如何？”或者点击一个按钮，而不再需要费力地组织长篇大论的提示。</p>
<p>所有复杂的“工程”工作都将退居幕后，为用户创造出一种仿佛“心有灵犀”的魔法般体验。而支撑这种魔法的，正是本报告所深入探讨的——严谨、系统、且至关重要的上下文工程。</p>
<h4><strong>引用的著作</strong></h4>
<ol>
<li>Karpathy: &quot;context engineering&quot; over &quot;prompt engineering&quot; | Hacker ..., 访问时间为 六月 26, 2025， <a href="https://news.ycombinator.com/item?id=44379538">https://news.ycombinator.com/item?id=44379538</a>  </li>
<li>访问时间为 一月 1, 1970， <a href="https://twitter.com/karpathy/status/1937902205765607626">https://twitter.com/karpathy/status/1937902205765607626</a>  </li>
<li>What is Context Engineering? The new Vibe Coding | by Mehul Gupta | Data Science in Your Pocket - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/data-science-in-your-pocket/what-is-context-engineering-the-new-vibe-coding-8d04421b6a11">https://medium.com/data-science-in-your-pocket/what-is-context-engineering-the-new-vibe-coding-8d04421b6a11</a>  </li>
<li>AI | Dan Calle, 访问时间为 六月 26, 2025， <a href="http://dancalle.com/tag/ai/">http://dancalle.com/tag/ai/</a>  </li>
<li>AI Context Engineering: Key Questions to Ask | TikTok, 访问时间为 六月 26, 2025， <a href="https://www.tiktok.com/@nate.b.jones/video/7518121865790131486">https://www.tiktok.com/@nate.b.jones/video/7518121865790131486</a>  </li>
<li>medium.com, 访问时间为 六月 26, 2025， <a href="https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b#:~:text=Prompt%20engineering%20primarily%20refers%20to,prompt%20to%20give%20precise%20output.">https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b#:~:text=Prompt%20engineering%20primarily%20refers%20to,prompt%20to%20give%20precise%20output.</a>  </li>
<li>Effective Prompts for AI: The Essentials - MIT Sloan Teaching &amp; Learning Technologies, 访问时间为 六月 26, 2025， <a href="https://mitsloanedtech.mit.edu/ai/basics/effective-prompts/">https://mitsloanedtech.mit.edu/ai/basics/effective-prompts/</a>  </li>
<li>Understanding Prompting, Prompt Engineering and In-Context Learning in LLMs - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/codex/understanding-prompting-prompt-engineering-and-in-context-learning-in-llms-2b59fb398fef">https://medium.com/codex/understanding-prompting-prompt-engineering-and-in-context-learning-in-llms-2b59fb398fef</a>  </li>
<li>I am Choosing 'Context Engineering' over 'Prompt Engineering'! | by ..., 访问时间为 六月 26, 2025， <a href="https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b">https://medium.com/@manish434k/i-am-choosing-context-engineering-over-prompt-engineering-7b4a10250e0b</a>  </li>
<li>Prompt engineering will be obsolete? : r/PromptEngineering - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/PromptEngineering/comments/1ldgn7t/prompt_engineering_will_be_obsolete/">https://www.reddit.com/r/PromptEngineering/comments/1ldgn7t/prompt_engineering_will_be_obsolete/</a>  </li>
<li>Don't Build Multi-Agents - Cognition, 访问时间为 六月 26, 2025， <a href="https://cognition.ai/blog/dont-build-multi-agents">https://cognition.ai/blog/dont-build-multi-agents</a>  </li>
<li>Beyond Prompts: The Rise of Context Engineering​​ | by Nileshk | Jun, 2025 | Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/@nileshk77487/beyond-prompts-the-rise-of-context-engineering-06050a5d59b6">https://medium.com/@nileshk77487/beyond-prompts-the-rise-of-context-engineering-06050a5d59b6</a>  </li>
<li>The rise of &quot;context engineering&quot; - LangChain Blog, 访问时间为 六月 26, 2025， <a href="https://blog.langchain.com/the-rise-of-context-engineering/">https://blog.langchain.com/the-rise-of-context-engineering/</a>  </li>
<li>What Actually Matters When You Scale? : r/aipromptprogramming - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/aipromptprogramming/comments/1l732wf/what_actually_matters_when_you_scale/">https://www.reddit.com/r/aipromptprogramming/comments/1l732wf/what_actually_matters_when_you_scale/</a>  </li>
<li>Stop Prompting, Start Engineering: 15 Principles to Deliver Your AI Agent to Production, 访问时间为 六月 26, 2025， <a href="https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production">https://hackernoon.com/stop-prompting-start-engineering-15-principles-to-deliver-your-ai-agent-to-production</a>  </li>
<li>10 RAG examples and use cases from real companies - Evidently AI, 访问时间为 六月 26, 2025， <a href="https://www.evidentlyai.com/blog/rag-examples">https://www.evidentlyai.com/blog/rag-examples</a>  </li>
<li>cloud.google.com, 访问时间为 六月 26, 2025， <a href="https://cloud.google.com/use-cases/retrieval-augmented-generation#:~:text=RAG%20(Retrieval%2DAugmented%20Generation),large%20language%20models%20(LLMs).">https://cloud.google.com/use-cases/retrieval-augmented-generation#:~:text=RAG%20(Retrieval%2DAugmented%20Generation),large%20language%20models%20(LLMs).</a>  </li>
<li>What is Retrieval-Augmented Generation (RAG)? | Google Cloud, 访问时间为 六月 26, 2025， <a href="https://cloud.google.com/use-cases/retrieval-augmented-generation">https://cloud.google.com/use-cases/retrieval-augmented-generation</a>  </li>
<li>Retrieval-augmented generation - Wikipedia, 访问时间为 六月 26, 2025， <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">https://en.wikipedia.org/wiki/Retrieval-augmented_generation</a>  </li>
<li>What is Retrieval Augmented Generation (RAG)? - Databricks, 访问时间为 六月 26, 2025， <a href="https://www.databricks.com/glossary/retrieval-augmented-generation-rag">https://www.databricks.com/glossary/retrieval-augmented-generation-rag</a>  </li>
<li>What is RAG? - Retrieval-Augmented Generation AI Explained - AWS, 访问时间为 六月 26, 2025， <a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/">https://aws.amazon.com/what-is/retrieval-augmented-generation/</a>  </li>
<li>What is retrieval-augmented generation (RAG)? - McKinsey, 访问时间为 六月 26, 2025， <a href="https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-retrieval-augmented-generation-rag">https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-retrieval-augmented-generation-rag</a>  </li>
<li>Advanced RAG Techniques - Guillaume Laforge, 访问时间为 六月 26, 2025， <a href="https://glaforge.dev/talks/2024/10/14/advanced-rag-techniques/">https://glaforge.dev/talks/2024/10/14/advanced-rag-techniques/</a>  </li>
<li>Advanced RAG Techniques - Cazton, 访问时间为 六月 26, 2025， <a href="https://www.cazton.com/blogs/technical/advanced-rag-techniques">https://www.cazton.com/blogs/technical/advanced-rag-techniques</a>  </li>
<li>Retrieval Augmented Generation use cases for enterprise - Indigo.ai, 访问时间为 六月 26, 2025， <a href="https://indigo.ai/en/blog/retrieval-augmented-generation/">https://indigo.ai/en/blog/retrieval-augmented-generation/</a>  </li>
<li>Advanced RAG Techniques - DataCamp, 访问时间为 六月 26, 2025， <a href="https://www.datacamp.com/blog/rag-advanced">https://www.datacamp.com/blog/rag-advanced</a>  </li>
<li>Advanced RAG Techniques - Weaviate, 访问时间为 六月 26, 2025， <a href="https://weaviate.io/blog/advanced-rag">https://weaviate.io/blog/advanced-rag</a>  </li>
<li>NirDiamant/RAG_Techniques: This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses. - GitHub, 访问时间为 六月 26, 2025， <a href="https://github.com/NirDiamant/RAG_Techniques">https://github.com/NirDiamant/RAG_Techniques</a>  </li>
<li>The Human-AI Partnership: Redefining Developer Roles in the Age of Autonomous Coding Agents - Zencoder, 访问时间为 六月 26, 2025， <a href="https://zencoder.ai/blog/human-ai-partnership-redefining-developer-roles">https://zencoder.ai/blog/human-ai-partnership-redefining-developer-roles</a>  </li>
<li>Function Calling with Open-Source LLMs - BentoML, 访问时间为 六月 26, 2025， <a href="https://bentoml.com/blog/function-calling-with-open-source-llms">https://bentoml.com/blog/function-calling-with-open-source-llms</a>  </li>
<li>LLM Agent vs Function Calling: Key Differences &amp; Use Cases - PromptLayer, 访问时间为 六月 26, 2025， <a href="https://blog.promptlayer.com/llm-agents-vs-function-calling/">https://blog.promptlayer.com/llm-agents-vs-function-calling/</a>  </li>
<li>Function Calling with LLMs - Prompt Engineering Guide, 访问时间为 六月 26, 2025， <a href="https://www.promptingguide.ai/applications/function_calling">https://www.promptingguide.ai/applications/function_calling</a>  </li>
<li>Function Calling in LLMs – Real Use Cases and Value? : r/AI_Agents - Reddit, 访问时间为 六月 26, 2025， <a href="https://www.reddit.com/r/AI_Agents/comments/1iio39z/function_calling_in_llms_real_use_cases_and_value/">https://www.reddit.com/r/AI_Agents/comments/1iio39z/function_calling_in_llms_real_use_cases_and_value/</a>  </li>
<li>Function calling - OpenAI API, 访问时间为 六月 26, 2025， <a href="https://platform.openai.com/docs/guides/function-calling">https://platform.openai.com/docs/guides/function-calling</a>  </li>
<li>GPT-5 coming this summer- Weekly AI Newsletter (June 23rd 2025) - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/nlplanet/gpt-5-coming-this-summer-weekly-ai-newsletter-june-23rd-2025-7c539b073b09">https://medium.com/nlplanet/gpt-5-coming-this-summer-weekly-ai-newsletter-june-23rd-2025-7c539b073b09</a>  </li>
<li>Data in the generative AI era: We need more knowledge engineers - SiliconANGLE, 访问时间为 六月 26, 2025， <a href="https://siliconangle.com/2025/02/04/data-generative-ai-era-need-knowledge-engineers/">https://siliconangle.com/2025/02/04/data-generative-ai-era-need-knowledge-engineers/</a>  </li>
<li>Advanced RAG: Best Practices for Production Ready Systems, 访问时间为 六月 26, 2025， <a href="https://www.getsubatomic.ai/blog-posts/advanced-rag">https://www.getsubatomic.ai/blog-posts/advanced-rag</a>  </li>
<li>Search Context Size - Perplexity, 访问时间为 六月 26, 2025， <a href="https://docs.perplexity.ai/guides/search-context-size-guide">https://docs.perplexity.ai/guides/search-context-size-guide</a>  </li>
<li>Perplexity AI and Its Impact on Search Engines - SmythOS, 访问时间为 六月 26, 2025， <a href="https://smythos.com/ai-agents/ai-tutorials/perplexity-ai/">https://smythos.com/ai-agents/ai-tutorials/perplexity-ai/</a>  </li>
<li>How does Perplexity work? | Perplexity Help Center, 访问时间为 六月 26, 2025， <a href="https://www.perplexity.ai/help-center/en/articles/10352895-how-does-perplexity-work">https://www.perplexity.ai/help-center/en/articles/10352895-how-does-perplexity-work</a>  </li>
<li>What Makes Perplexity AI a Revolutionary Search Engine? - Pageon.ai, 访问时间为 六月 26, 2025， <a href="https://www.pageon.ai/blog/perplexity-ai-search-engine-08u7f">https://www.pageon.ai/blog/perplexity-ai-search-engine-08u7f</a>  </li>
<li>What is Perplexity AI? How to use it + how it works - Zapier, 访问时间为 六月 26, 2025， <a href="https://zapier.com/blog/perplexity-ai/">https://zapier.com/blog/perplexity-ai/</a>  </li>
<li>Perplexity AI Review: How the AI Search Engine Works? | WPS Office Blog, 访问时间为 六月 26, 2025， <a href="https://www.wps.ai/blog/perplexity-ai-review-how-the-ai-search-engine-works/">https://www.wps.ai/blog/perplexity-ai-review-how-the-ai-search-engine-works/</a>  </li>
<li>Context Engineering and Domain Expertise in Generative AI-Powered Software Development - My Framer Site - XponentL Data, 访问时间为 六月 26, 2025， <a href="https://xponentl.ai/news/context-engineering-and-domain-expertise-in-generative-ai-powered-software-development">https://xponentl.ai/news/context-engineering-and-domain-expertise-in-generative-ai-powered-software-development</a>  </li>
<li>Why Context Engineering Matters - YouTube, 访问时间为 六月 26, 2025， <a href="https://www.youtube.com/watch?v=fYgsZnkFeck">https://www.youtube.com/watch?v=fYgsZnkFeck</a>  </li>
<li>1 Introduction and objectives 2 Context and engineering design research issues., 访问时间为 六月 26, 2025， <a href="https://www.designsociety.org/download-publication/24116/A+SURVEY+OF+CONTEXT+MODELING%3A+APPROACHES%2C+THEORIES+AND+USE+FOR+ENGINEERING+DESIGN+RESEARCHES.">https://www.designsociety.org/download-publication/24116/A+SURVEY+OF+CONTEXT+MODELING%3A+APPROACHES%2C+THEORIES+AND+USE+FOR+ENGINEERING+DESIGN+RESEARCHES.</a>  </li>
<li>Characterizing Proof-of-Concept Practices using the Lens of Context Engineering - Estudo Geral, 访问时间为 六月 26, 2025， <a href="https://estudogeral.uc.pt/bitstream/10316/113037/1/Characterizing%20Proof-of-Concept%20Practices%20using%20the%20Lens%20of%20Conte.pdf">https://estudogeral.uc.pt/bitstream/10316/113037/1/Characterizing%20Proof-of-Concept%20Practices%20using%20the%20Lens%20of%20Conte.pdf</a>  </li>
<li>&quot;Relevance, Works and Context Engineering&quot; by Michael K. Buckland and Wayne de Fremery - IdeaExchange@UAkron, 访问时间为 六月 26, 2025， <a href="https://ideaexchange.uakron.edu/docam/vol11/iss2/5/">https://ideaexchange.uakron.edu/docam/vol11/iss2/5/</a>  </li>
<li>SYSTEMS ENGINEERING AND MANAGEMENT DEFINITIONS - Project Performance International (PPI), 访问时间为 六月 26, 2025， <a href="https://www.ppi-int.com/wp-content/uploads/2023/05/PPI-007725-7-SEM-Definitions-221017-SE5D-3.pdf">https://www.ppi-int.com/wp-content/uploads/2023/05/PPI-007725-7-SEM-Definitions-221017-SE5D-3.pdf</a></li>
</ol>
</details>
<hr />
<details>
  <summary>SWE-agent深度解析：从代理-计算机接口到AI驱动软件工程的新前沿 (Gemini Deep Research - 仅供参考)</summary>
<h1><strong>SWE-agent深度解析：从代理-计算机接口到AI驱动软件工程的新前沿</strong></h1>
<h2><strong>第一部分：SWE-agent简介：自动化软件工程的范式转移</strong></h2>
<h3><strong>1.1 定义SWE-agent</strong></h3>
<p>SWE-agent是一个由普林斯顿大学和斯坦福大学的研究人员开发和维护的开源项目 1。它被定义为一个自主系统，旨在赋能大型语言模型（Large Language Model, LM）扮演软件工程代理的角色，通过自主使用工具来解决真实GitHub代码库中的问题 1。该系统的应用范围不仅限于修复软件缺陷（bug fixing），还扩展到了网络安全挑战（如夺旗赛）和编程竞赛等领域 2。作为一个研究导向的工具，SWE-agent的设计理念是“自由流畅且可泛化”，即给予语言模型最大的自主权；同时它也是“可配置且文档齐全的”，其行为主要由一个YAML配置文件控制，并以“简单且易于修改”为设计目标，从而方便学术界进行二次开发和研究 1。</p>
<h3><strong>1.2 核心论点：将大型语言模型视为一类新型终端用户</strong></h3>
<p>SWE-agent项目的核心哲学论点是，大型语言模型代表了一类全新的“终端用户”，它们拥有与人类用户截然不同的需求和能力 4。正如人类开发者受益于集成开发环境（Integrated Development Environments, IDEs）等强大的软件应用来处理复杂的软件工程任务一样，语言模型代理也需要为其量身定制的接口，以便与代码库等复杂的数字环境进行高效交互 4。这一核心思想构成了整个项目的理论基础，并为其最主要的创新——代理-计算机接口（Agent-Computer Interface, ACI）的提出提供了理论依据。</p>
<p>这种观念的转变是深刻的。在此之前，许多系统将代码任务视为一个单向的生成过程：输入一个提示，输出一段代码。然而，软件工程的本质远不止于此，它是一个涉及探索、调试、测试和迭代的复杂过程。SWE-agent的提出，标志着业界开始将软件工程任务重新定义为一个代理与其环境之间的持续、有状态的对话。这种对话的质量，很大程度上取决于两者之间的交互媒介。因此，SWE-agent的真正突破并非仅仅是提出一个更优的模型或提示工程技巧，而是创建了一个全新的交互范式，承认了软件工程的探索性本质，并为语言模型提供了有效参与这一过程的工具和接口。从静态生成到动态交互的飞跃，为后续所有相关研究的进展奠定了基础。</p>
<h3><strong>1.3 初步影响与业界领先（SOTA）性能</strong></h3>
<p>SWE-agent一经发布，便在业界产生了显著影响。它在SWE-bench基准测试上取得了当时最先进（State-of-the-Art, SOTA）的性能，这是一个包含真实世界GitHub问题的挑战性数据集 1。使用GPT-4 Turbo作为后端模型，SWE-agent成功解决了2,294个任务中的12.47%，这一成绩远超此前由非交互式、检索增强系统创下的3.8%的最佳纪录 8。这一突破性成果不仅验证了项目核心论点的正确性，也为整个领域设立了新的性能基准。从其后续发布的新闻来看，SWE-agent持续与多种业界领先模型（如GPT-4o、Claude 3系列）结合，并不断刷新SWE-bench的最高分纪录，甚至推出了性能卓越的开源权重模型SWE-agent-LM-32b，进一步巩固了其在开源项目中的领先地位 1。</p>
<h3><strong>1.4 关键特性</strong></h3>
<p>SWE-agent项目具备几个鲜明的特点，使其在众多AI编码工具中脱颖而出。首先，它具有<strong>自由流畅和高度泛化</strong>的能力，这意味着框架本身不对语言模型的行为做过多限制，从而最大限度地保留了模型的自主决策能力 1。其次，系统具有</p>
<p><strong>高度可配置性</strong>，整个代理的行为逻辑和工具集都通过一个统一的YAML配置文件进行管理，方便用户根据不同任务进行定制 1。最后，该项目</p>
<p><strong>为研究而生</strong>，其代码设计简洁明了，易于修改和扩展（hackable by design），这极大地促进了学术界在此基础上进行进一步的研究和创新 1。</p>
<h2><strong>第二部分：代理-计算机接口（ACI）：SWE-agent的架构基石</strong></h2>
<h3><strong>2.1 ACI概念框架</strong></h3>
<p>代理-计算机接口（Agent-Computer Interface, ACI）是SWE-agent项目的核心创新和架构基石。它被定义为专为大型语言模型代理设计的、用于与计算机进行交互的接口，其核心功能是明确规定代理可用的命令集以及环境反馈的格式 8。ACI的设计理念与传统面向人类用户的界面（如图形用户界面GUI和标准Linux命令行）形成了鲜明对比。GUI富含视觉元素和复杂的工作流，对于纯文本处理的语言模型而言难以解析和导航；而Linux命令行虽然是基于文本的，但其命令通常包含大量选项，输出信息冗长，很容易超出语言模型有限的上下文窗口，从而干扰其对核心任务的专注 9。</p>
<p>因此，ACI的提出是一项深思熟虑的设计决策，其目标是在不修改底层语言模型权重的前提下，通过优化交互接口来显著提升代理的性能 8。ACI的真正功能可以被理解为一个“阻抗匹配”层，它巧妙地连接了两个性质迥异的系统：一个是大型语言模型的概率性、高层次、有时非确定性的推理能力，另一个是计算机文件系统和命令行的确定性、低层次、不容错误的执行环境。</p>
<p>语言模型基于词元（token）和统计规律进行操作，它无法像人类一样真正“理解”文件系统的结构。因此，它很容易生成语法上看似合理但语义上完全错误的命令（例如，为grep命令提供一个不存在的参数）。而计算机的命令行环境则是严格字面的，任何一个微小的错误都会导致命令失败。这种不匹配造成了巨大的“阻抗”：语言模型模糊的输出意图被计算机刚性的输入要求频繁拒绝，导致大量的无效尝试和任务失败。</p>
<p>ACI的设计原则正是为了解决这种不匹配。通过提供“简单的命令”，它减小了语言模型出错的可能性；通过返回“简洁的反馈”，它将计算机的状态高效地翻译成模型可以消化的词元摘要；通过内置“防护栏”，它在接口层面拦截错误，防止其破坏代理的整个任务规划。因此，ACI不仅仅是一套工具，更是一个翻译和缓冲层。它有效地降低了两个系统之间的“阻抗”，使得语言模型的“推理能量”能够顺畅地流入“编码任务”这个系统中，并将过程中的损耗（即错误和无效的交互回合）降至最低。这从根本上解释了为何ACI相比于原始的命令行环境，能够带来如此显著的性能提升。</p>
<h3><strong>2.2 ACI的核心设计原则</strong></h3>
<p>通过对代理行为的手动检查和网格搜索优化，SWE-agent的研究者们提炼出了构建高效ACI的四条核心设计原则 6。</p>
<ol>
<li><strong>动作应简单易懂 (Simple and Easy-to-Understand Actions):</strong> ACI提供的命令应该只有少数几个选项和简洁明了的文档。这使得语言模型更容易正确地使用它们，而无需依赖大量的示例（demonstrations）或复杂的微调。这与许多拥有数十个参数选项的bash命令形成了鲜明对比，后者对模型来说极易产生混淆和误用 6。  </li>
<li><strong>操作应紧凑高效 (Compact and Efficient Operations):</strong> 重要的、高层次的操作（如文件导航和代码编辑）应被整合成尽可能少的动作。高效的动作能帮助代理在单个交互回合内取得实质性进展，避免了为完成一个高阶操作而需要组合多个简单动作、跨越数个回合的低效循环 6。  </li>
<li><strong>环境反馈应信息丰富且简洁 (Informative and Concise Environment Feedback):</strong> ACI必须为代理提供关于当前环境状态及其最近动作效果的、有意义的反馈。反馈内容应高度相关且简洁，避免不必要的冗余信息。例如，当代理编辑一个文件后，ACI会向其展示修改处附近的代码片段，而不是整个文件的内容，这有助于代理理解其修改所带来的影响，同时有效利用宝贵的上下文窗口 6。  </li>
<li><strong>内置防护栏以减少错误传播 (Proactive Guardrails for Error Mitigation):</strong> 与人类一样，语言模型在编辑或搜索时也会犯错，并且往往难以从错误中恢复。ACI通过内置防护栏机制来主动预防常见错误并帮助代理恢复。一个关键例子是集成的代码语法检查器（linter），它可以在代理提交编辑后立即检测出语法错误并返回提示，帮助代理快速识别并纠正问题，从而避免了错误状态的持续传播 6。</li>
</ol>
<h3><strong>2.3 ACI命令套件</strong></h3>
<p>ACI的命令套件是其设计原则的具体体现，它为语言模型提供了一套专门用于软件工程任务的工具。</p>
<ul>
<li><strong>搜索与导航 (Search and Navigation):</strong> 为了解决在大型代码库中定位相关文件和代码片段的难题，ACI引入了find_file、search_file和search_dir等专用命令。这些命令与传统的grep或find不同，它们返回的是经过处理的搜索结果摘要，而非可能淹没上下文窗口的原始输出流，从而极大地简化了信息定位过程 6。  </li>
<li><strong>文件查看器 (File Viewer):</strong> ACI的文件查看器经过精心设计，以适应语言模型的上下文限制。它不会一次性显示整个文件内容，而是提供一个可滚动的代码行“窗口”。代理可以通过滚动指令来查看文件的不同部分，这种聚焦式的方法可以防止代理被大型文件所压垮，确保其有限的上下文窗口被高效利用 11。  </li>
<li><strong>文件编辑器 (File Editor):</strong> 文件编辑是ACI的核心功能之一。它被设计得既简单又健壮，通常以行号或代码块为单位进行操作。更重要的是，它紧密集成了之前提到的防护栏机制，如语法检查。当编辑操作导致语法错误时，系统会立即返回明确的错误信息，指导模型进行修正 8。  </li>
<li><strong>命令执行 (Execution):</strong> SWE-agent构建于Linux命令行之上，因此在需要时仍然可以访问标准的bash命令。然而，ACI为执行测试等关键操作提供了结构化的方式，它能够捕获命令的输出，并将其整理成干净、易于模型解析的格式，从而方便模型对测试结果进行分析和决策 8。</li>
</ul>
<p>下表详细对比了ACI命令与标准Shell命令，以突显ACI为语言模型所做的优化设计。</p>
<p><strong>表2.1: ACI命令套件与标准Shell命令对比</strong></p>
<table>
<thead>
<tr>
<th align="left">ACI 命令/工具</th>
<th align="left">功能及面向LM的设计</th>
<th align="left">可比的Shell命令</th>
<th align="left">ACI优势 (为何对LM更优)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">search_file / search_dir</td>
<td align="left">在文件或目录中搜索字符串，返回包含匹配项及其行号的简洁摘要。</td>
<td align="left">grep, find</td>
<td align="left">避免冗长的原始输出，提供结构化的反馈，减少了模型混淆复杂命令参数的可能性，专注于核心信息。</td>
</tr>
<tr>
<td align="left">文件编辑器</td>
<td align="left">提供基于行号或代码块的编辑功能，并内置语法检查器，对失败的编辑提供即时、明确的错误反馈。</td>
<td align="left">sed, awk, vim, nano</td>
<td align="left">简化了复杂的流编辑语法，集成了错误检查机制，防止错误状态传播，降低了模型进行有效代码修改的难度。</td>
</tr>
<tr>
<td align="left">文件查看器</td>
<td align="left">提供一个可滚动的代码“窗口”，而不是一次性加载整个文件，并始终显示当前打开的文件和行号。</td>
<td align="left">cat, less, more</td>
<td align="left">节约了宝贵的上下文空间，帮助模型在大型文件中保持定位感，避免因信息过载而“分心”。</td>
</tr>
<tr>
<td align="left">测试执行器</td>
<td align="left">以结构化方式执行测试脚本，捕获并格式化输出，清晰地呈现成功或失败的测试用例。</td>
<td align="left">直接执行 pytest 或其他测试框架</td>
<td align="left">将混乱的测试日志解析为清晰、简洁的摘要，使模型能够轻松判断其代码修改是否解决了问题。</td>
</tr>
</tbody></table><p>数据来源: 6</p>
<h3><strong>2.4 运行机制</strong></h3>
<p>SWE-agent的有效运行依赖于两个关键机制：ReAct框架和上下文管理。</p>
<ul>
<li><strong>ReAct框架:</strong> SWE-agent遵循ReAct（Reasoning and Acting）思想范式。在交互的每一步，语言模型都会生成一个“思考（thought）”和一个“命令（command）”。“思考”是模型对当前状态的分析、推理和下一步计划的阐述，“命令”则是它决定要执行的具体ACI动作 9。这种模式使得代理的决策过程更加透明，也便于分析其行为逻辑。  </li>
<li><strong>上下文管理与历史记录折叠:</strong> 这是ACI一个至关重要但又不易察觉的特性。为了在语言模型有限的上下文窗口内进行长序列的交互，ACI采用了一种“历史记录折叠”的策略。当交互历史过长时，它会将较早的、重要性较低的交互回合（包括命令和环境反馈）折叠成一条占位符消息，例如“之前的15个回合已折叠”。与此同时，最近的几个交互回合则会完整地保留在上下文中。这种机制确保了模型在做决策时，既能感知到最近发生的情况，又不会被过时的信息所干扰，从而在保持任务相关性的同时，显著降低了每次推理的计算成本 12。</li>
</ul>
<h2><strong>第三部分：SWE-bench生态系统：软件工程代理的严苛试炼场</strong></h2>
<h3><strong>3.1 概述与目标</strong></h3>
<p>SWE-bench是用于评估SWE-agent及其同类产品的核心基准测试 13。它并非一个人工合成的数据集，而是完全源于真实世界的软件开发场景。该基准测试从GitHub上12个广受欢迎的Python项目中收集了2,294个“问题-拉取请求”（Issue-Pull Request）配对 13。其核心任务是：给定一个代码库的特定版本和一个用自然语言描述的GitHub Issue，要求AI代理生成一个代码补丁（patch），以解决该Issue中描述的问题 15。这一设定极大地考验了AI代理的代码理解、推理、规划和代码生成能力。</p>
<p>SWE-bench的出现本身就是一次重要的学术贡献，因为它为评估AI软件工程师的能力提供了一个可量化、可复现的平台。但它的意义远不止于一个静态的评分标准。随着研究的深入，SWE-bench自身也在不断演进，其局限性反而成为了催生新一代基准和训练环境的强大动力。</p>
<p>最初的SWE-bench数据集规模庞大，运行一次完整的评估需要耗费大量计算资源，这使得研究人员难以进行快速的迭代和实验。为了解决这个问题，研究团队推出了<strong>SWE-bench Lite</strong>，一个规模更小、更易于管理的子集。当研究人员发现原始数据集中可能存在定义不清或难以解决的问题时，他们与OpenAI合作，通过人工验证的方式创建了<strong>SWE-bench Verified</strong>，确保了基准的高质量和可靠性。随后，为了应对AI代理可能对Python特定工具产生“过拟合”的风险，<strong>SWE-bench Multilingual</strong>应运而生，将评估范围扩展到多种编程语言。而<strong>SWE-bench Multimodal</strong>的出现，则进一步将挑战推向了包含视觉元素的软件领域。</p>
<p>然而，所有这些“bench”系列的数据集都有一个共同的根本性局限：它们只为<strong>评估</strong>而设计。数据集中只包含最终解决问题的代码补丁，却缺失了开发者为了写出这个补丁所经历的、一步一步的试错和探索过程。这一“过程数据”的缺失，使得直接在这些数据集上<strong>训练</strong>一个智能代理变得异常困难。正是这一局限性，直接催化了<strong>SWE-Gym</strong>的诞生。SWE-Gym不再仅仅提供问题和答案，而是提供了一个完整的、可执行的交互环境和奖励信号，从而将研究的重心从“如何评估代理”推向了“如何训练代理”的新阶段。因此，SWE-bench生态系统的发展历程，生动地展示了它如何作为一个活跃的研究催化剂，通过不断暴露自身的不足来持续推动整个领域向前发展。</p>
<h3><strong>3.2 SWE-bench数据集家族</strong></h3>
<p>随着时间的推移，SWE-bench已经从一个单一的数据集发展成为一个包含多个变体的“家族”，每个变体都有其特定的评估目标。</p>
<ul>
<li><strong>SWE-bench (Full):</strong> 这是最初的、最完整的数据集，包含全部2,294个实例，用于进行最全面的性能评估 13。  </li>
<li><strong>SWE-bench Lite:</strong> 这是一个精简的子集，最初包含300个实例，后来扩展到534个。它主要用于快速、低成本的评估和开发测试，其中的任务经过筛选，更侧重于功能性的、相对独立的软件缺陷修复 8。  </li>
<li><strong>SWE-bench Verified:</strong> 这是一个高质量的子集，包含了从测试集中精心挑选的500个实例。这些实例都经过了人类软件工程师的逐一验证，以确保问题描述清晰、任务可解。该数据集是与OpenAI的预备团队（Preparedness team）合作的产物，旨在提高基准测试结果的可靠性和公信力 15。  </li>
<li><strong>SWE-bench Multilingual:</strong> 这是一个多语言版本的数据集，包含来自9种不同编程语言（如C、C++、Go、Java、JavaScript等）的300个任务。它的设计目标是评估AI代理在非Python环境下的泛化能力，并防止研究社区过度拟合Python特有的工具链 19。  </li>
<li><strong>SWE-bench Multimodal:</strong> 这是一个前沿的变体，其任务中包含了截图、UI元素等视觉信息，旨在测试代理在处理涉及图形界面的软件任务时的能力。为了保证排行榜的公平性，其测试集的真实解（ground truth）保持私有，需要通过专门的命令行工具提交结果进行云端评估 15。</li>
</ul>
<p><strong>表3.1: SWE-bench 数据集变体</strong></p>
<table>
<thead>
<tr>
<th align="left">数据集变体</th>
<th align="left">规模</th>
<th align="left">构成与目标</th>
<th align="left">核心贡献</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">SWE-bench</td>
<td align="left">2,294个实例</td>
<td align="left">完整的测试集，用于全面、综合的性能评估。</td>
<td align="left">建立了领域内首个基于真实世界问题的软件工程基准。</td>
</tr>
<tr>
<td align="left">SWE-bench Lite</td>
<td align="left">534个实例</td>
<td align="left">精简的子集，用于快速迭代和开发。</td>
<td align="left">降低了评估成本，加速了研究周期。</td>
</tr>
<tr>
<td align="left">SWE-bench Verified</td>
<td align="left">500个实例</td>
<td align="left">经过人类专家验证的可解问题子集。</td>
<td align="left">提高了评估结果的可靠性和公信力。</td>
</tr>
<tr>
<td align="left">SWE-bench Multilingual</td>
<td align="left">300个实例</td>
<td align="left">包含9种编程语言的任务。</td>
<td align="left">推动了代理的跨语言泛化能力研究，防止了对Python的过拟合。</td>
</tr>
<tr>
<td align="left">SWE-bench Multimodal</td>
<td align="left">100个开发实例，500个测试实例</td>
<td align="left">包含截图等视觉信息的任务。</td>
<td align="left">将评估范围扩展到多模态软件工程领域。</td>
</tr>
</tbody></table><p>数据来源: 13</p>
<h3><strong>3.3 评估协议与可复现性</strong></h3>
<p>SWE-bench生态系统极为重视评估的科学性和严谨性。其评估协议的核心是通过单元测试进行验证，即以问题修复后（post-PR）的代码行为作为黄金标准（ground truth） 13。为了确保评估结果的可复现性，整个评估流程被完全容器化。每个测试实例都在一个独立的Docker容器中运行，该容器预装了项目所需的所有依赖。这种设计确保了无论在何种机器或操作系统上运行评估，都能得到一致的结果，这对于可信的学术基准至关重要 15。</p>
<p>同时，也需要指出，运行SWE-bench的评估对计算资源有较高的要求。官方建议，运行评估的机器至少需要120 GB的可用存储空间、16 GB的内存和8个CPU核心。这在一定程度上限制了个人研究者和小型团队的参与 15。</p>
<h2><strong>第四部分：竞争格局：SWE-agent在AI编码竞技场中的定位</strong></h2>
<h3><strong>4.1 SWE-agent vs. 专有系统（Devin AI）</strong></h3>
<p>在当前的AI软件工程师领域，SWE-agent与Cognition AI推出的Devin形成了鲜明的对比，代表了两种不同的发展路径：研究驱动的开源模式与产品驱动的商业模式。</p>
<ul>
<li><strong>设计哲学:</strong> SWE-agent是一个完全开源的项目，其代码、设计理念和研究成果都公之于众，旨在推动学术研究和社区协作 1。相比之下，Devin是一个闭源的商业产品，其内部技术细节和模型均不公开 20。  </li>
<li><strong>核心创新:</strong> SWE-agent向公众贡献的核心创新是其“代理-计算机接口”（ACI）的概念框架，这是一个经过严谨学术论证的、旨在提升AI代理性能的系统设计 8。而Devin的核心卖点是其宣称的端到端自主开发能力，能够从零开始构建、部署全栈应用，扮演一个近乎完全自主的软件工程师角色 23。  </li>
<li><strong>性能表现:</strong> 尽管Devin是闭源的，但它同样在SWE-bench上进行了性能测试并公布了结果。而SWE-agent作为一个开源项目，其在SWE-bench上的表现（例如一篇报道中提到的12.29%的解决率）展现出了极强的竞争力，证明了开源研究路线在解决复杂软件工程问题上的巨大潜力 20。</li>
</ul>
<h3><strong>4.2 SWE-agent vs. 其他开源替代品（Devika, OpenDevin）</strong></h3>
<p>在Devin发布后，开源社区迅速涌现出多个旨在复现其能力的项目，其中以Devika和OpenDevin最为知名。将SWE-agent与这些项目进行比较，可以更清晰地看到其独特的定位。</p>
<ul>
<li><strong>Devika:</strong> 该项目明确将自己定位为Devin的一个开源替代品 22。其一个显著的技术选择是使用Claude 3系列模型而非GPT-4，其开发者认为Claude 3在基准测试上表现更优，且拥有更大的上下文窗口 25。Devika的目标是复现Devin那种完整的、能够自主研究并编写代码的“代理软件工程师”工作流 22。  </li>
<li><strong>OpenDevin:</strong> 这是一个由社区驱动的开源项目，其目标同样是复现Devin的能力，但更强调开源协作的价值和过程的透明性 21。  </li>
<li><strong>SWE-agent的独特定位:</strong> 与上述项目相比，SWE-agent的初始目标更为专注和深入。它并非为了复现某个已有的产品，而是源于一个基础性的学术问题——如何为AI代理设计更高效的计算机交互接口。因此，它贡献了ACI这一全新的概念，并专注于通过该接口解决GitHub上的实际问题。这使其成为一个在学术上更为严谨、在技术上更为专精的工具，尽管其框架本身具备良好的泛化能力 1。</li>
</ul>
<p>这种分野揭示了开源生态系统在应对强大的商业产品时的一种内在分化。当一个像Devin这样的颠覆性闭源产品出现时，开源社区的反应通常分为两类。第一类是“复现者”（Replicators），如Devika和OpenDevin，它们的目标是追赶并民主化该产品的能力，让更广泛的开发者能够免费使用类似的功能。它们的使命由一个已存在的产品所定义。</p>
<p>第二类是“创新者”（Innovators），SWE-agent恰好是这一类的典型代表。它的诞生并非为了应对某个商业竞争对手，而是源于普林斯顿和斯坦福大学的学术探索，旨在解决一个更根本的科学问题：如何构建语言模型与计算机之间的高效桥梁 1。它的使命由一个待解的科学问题所驱动。</p>
<p>这两条发展路径——“复现”与“创新”——共同构成了健康且充满活力的开源生态。复现者确保了前沿技术不会被少数公司垄断，而创新者则负责开拓全新的疆域，提出可能定义下一代技术范式的原创思想。从长远来看，正是SWE-agent及其后续研究所代表的“创新者”路径，更能推动整个领域进入未知的、更广阔的发展空间。</p>
<p><strong>表4.1: 主流AI软件工程代理对比分析</strong></p>
<table>
<thead>
<tr>
<th align="left">代理</th>
<th align="left">开发模式</th>
<th align="left">核心创新/焦点</th>
<th align="left">底层LM (已知)</th>
<th align="left">目标工作流</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>SWE-agent</strong></td>
<td align="left">大学研究，开源</td>
<td align="left">代理-计算机接口 (ACI)</td>
<td align="left">模型无关 (支持GPT-4, Claude等)</td>
<td align="left">解决GitHub Issues，可泛化</td>
</tr>
<tr>
<td align="left"><strong>Devin AI</strong></td>
<td align="left">商业公司，闭源</td>
<td align="left">端到端全栈应用自主开发</td>
<td align="left">专有 (可能基于GPT-4)</td>
<td align="left">全栈应用开发、部署</td>
</tr>
<tr>
<td align="left"><strong>Devika</strong></td>
<td align="left">个人/初创公司，开源</td>
<td align="left">基于Claude 3的代理工作流</td>
<td align="left">Claude 3</td>
<td align="left">AI结对程序员，项目开发</td>
</tr>
<tr>
<td align="left"><strong>OpenDevin</strong></td>
<td align="left">社区驱动，开源</td>
<td align="left">社区协作复现Devin能力</td>
<td align="left">支持多种模型</td>
<td align="left">通用软件开发</td>
</tr>
</tbody></table><p>数据来源: 1</p>
<h2><strong>第五部分：新前沿：SWE代理的最新进展与演化</strong></h2>
<p>SWE-agent的发布开启了AI驱动软件工程的新篇章，但研究的步伐并未就此停歇。在随后的时间里，该领域经历了一系列快速的演进，研究重心不断提升和抽象，形成了一个从具体问题到更高层级挑战的良性发展循环。</p>
<p>这一过程可以被看作是一个不断攀登抽象阶梯的历程。最初，<strong>第一层是接口（Interface）</strong>：SWE-agent通过其创新的ACI解决了AI代理与计算机进行有效交互的基础问题，这使得代理能够可靠地“行动”（Act）。当代理具备了行动能力后，新的问题随之而来：如何让它们的行动更智能、更有效？这就引出了<strong>第二层，即训练（Training）</strong>。为了让代理能够“学习”（Learn），研究社区开发了SWE-Gym，这是一个提供了可执行环境和奖励信号的训练场。有了学习的环境，下一个问题自然是：用什么来教？什么是最有效的教材？这便进入了<strong>第三层，即数据（Data）</strong>。Skywork-SWE项目通过构建大规模的“代理轨迹”数据集，并揭示了数据规模与代理性能之间的“数据定标法则”（Data Scaling Law），证明了通过扩大高质量训练数据可以有效地“规模化学习”（Scale the Learning）。最后，当研究者们拥有了能够通过规模化学习来构建强大代理的能力后，一个更具哲学性的问题摆在了面前：我们到底应该构建什么样的代理？是高度特化的“专家”，还是能力全面的“通才”？这就是<strong>第四层，即架构与哲学（Architecture/Philosophy）</strong>。USEagent项目通过提出“统一软件工程代理”的概念，试图回答这个问题，从而为规模化学习定义了更宏大的“目标”（Goal）。</p>
<p>这个从“接口”到“训练”，再到“数据”，最终到“架构”的演进路径，清晰地展示了一个科研领域如何通过解决一个层面的具体问题，来为探索下一个更抽象层面的挑战创造工具和条件。这是一个经典的科学与工程进步模式，表明该领域正处于一个高速发展的、充满活力的阶段。</p>
<h3><strong>5.1 从评估到训练的转变：SWE-Gym与AgentGym</strong></h3>
<p>领域发展的第一个关键转变，是从仅仅关注<strong>评估</strong>现有模型，转向如何<strong>训练</strong>或<strong>微调</strong>出更强大的AI代理。</p>
<ul>
<li><strong>SWE-Gym:</strong> 作为该领域的第一个专用训练环境，SWE-Gym的出现具有里程碑意义。它提供了2,438个源自真实世界的Python任务，每个任务都配备了完整的、可执行的运行时环境和单元测试。这使得研究人员能够收集代理在解决问题过程中的完整交互轨迹（即代理采取的一系列思考和行动），并利用这些轨迹数据进行监督式微调或强化学习 26。实验结果惊人地表明，仅仅使用从SWE-Gym中收集的数百条成功轨迹对开源模型进行微调，就能带来高达19%的绝对性能提升，这极大地推动了开源AI代理的发展 26。  </li>
<li><strong>AgentGym:</strong> 紧随其后，AgentGym进一步扩展了这一理念，提供了一个规模更大的训练环境，包含超过8,700个任务。这使得更大规模地训练开源SWE代理成为可能，并帮助研究者们在基准测试上取得了新的SOTA性能 29。</li>
</ul>
<h3><strong>5.2 揭示数据定标法则：Skywork-SWE的贡献</strong></h3>
<p>如果说SWE-Gym回答了“在哪里训练”的问题，那么Skywork-SWE项目则回答了“用什么训练”以及“训练多少”的问题。</p>
<ul>
<li><strong>问题与解决方案:</strong> 高质量训练数据（即成功的代理交互轨迹）的获取是一个巨大的瓶颈 30。Skywork-SWE项目通过设计一个自动化的数据管理流水线，成功构建了一个包含10,169个实例和超过8,000条成功代理轨迹的大规模数据集 31。  </li>
<li><strong>核心发现:</strong> 该研究最重要的贡献是揭示了软件工程任务中的<strong>数据定标法则</strong>。研究表明，随着训练所用的代理轨迹数据量的增加，模型的性能也随之持续提升，并且在当前的数据规模下远未达到饱和 30。这是一个根本性的发现，它意味着当前AI代理的性能主要受限于数据，只要能持续扩大高质量训练数据的规模，其能力就有望得到进一步的显著提升。  </li>
<li><strong>成果:</strong> 基于这一发现，研究团队在该数据集上微调的Skywork-SWE-32B模型，在不使用复杂推理时搜索策略的情况下，就在SWE-bench Verified上取得了38.0%的解决率；在结合了测试时计算（TTS）等技术后，其性能更是达到了47.0%，一举超越了许多参数量远大于它的模型，为开源模型的发展树立了新的标杆 30。</li>
</ul>
<h3><strong>5.3 超越特化：向统一代理（USEagent）的迈进</strong></h3>
<p>随着AI代理能力的不断增强，研究的焦点开始从构建解决特定问题（如修复bug）的“专家”代理，转向构建能够处理多种任务的“通才”代理。</p>
<ul>
<li><strong>核心问题:</strong> USEagent项目开宗明义地提出了一个深刻的问题：“一个大型语言模型代理等同于一个AI软件工程师吗？” 33。  </li>
<li><strong>愿景:</strong> 该项目旨在构建一个<strong>统一软件工程代理（Unified Software Engineering agent, USEagent）</strong>，它能够协调和处理多种软件工程能力，如编码、测试、打补丁等，而不仅仅是执行单一任务。其最终愿景是创造一个能够处理复杂、多步骤开发场景的、可以作为人类团队一员的“AI队友” 33。  </li>
<li><strong>方法论:</strong> 为了评估这种统一代理，研究人员还构建了一个名为<strong>USEbench</strong>的元基准测试，它整合了来自SWE-bench、SWT-bench等多个基准的任务，以全面考察代理的多方面能力 33。初步结果显示，USEagent在处理其特化任务时，性能与专门的代理相当，同时还具备更广泛的通用性 34。</li>
</ul>
<h3><strong>5.4 先进的推理与框架技术</strong></h3>
<p>除了上述宏观层面的演进，一些具体的工程技术也在推动着性能的提升。</p>
<ul>
<li><strong>测试时计算扩展（Test-Time Scaling, TTS）:</strong> 这是一种在推理阶段投入更多计算资源来换取更高性能的技术。典型的做法是让代理生成多个候选解决方案，然后使用一个“验证器”（verifier）模型来评估并选出最优的一个。事实证明，这种方法能够显著提升最终的问题解决率 30。  </li>
<li><strong>代理框架的重要性:</strong> 最新的研究也开始强调，承载语言模型的代理框架（如SWE-agent、OpenHands、AutoCodeRover等）本身就是一个至关重要的变量。不同的框架有不同的工作流和工具集，其设计优劣对最终性能的影响，有时甚至不亚于底层语言模型本身的选择 26。</li>
</ul>
<p><strong>表5.1: SWE-agent发布后的基础性研究进展总结</strong></p>
<table>
<thead>
<tr>
<th align="left">研究项目/概念</th>
<th align="left">核心贡献</th>
<th align="left">对领域的发现/启示</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><strong>SWE-Gym</strong></td>
<td align="left">首个用于训练SWE代理的可执行环境。</td>
<td align="left">将研究重心从“评估”转向“训练”，为开源模型的性能提升开辟了新路径。</td>
</tr>
<tr>
<td align="left"><strong>Skywork-SWE / 数据定标</strong></td>
<td align="left">构建了超大规模的代理轨迹数据集，并发现了数据定标法则。</td>
<td align="left">证明了当前代理性能受数据限制；获取更多高质量数据是提升能力的关键。</td>
</tr>
<tr>
<td align="left"><strong>USEagent / 统一代理</strong></td>
<td align="left">提出了用于处理多种软件工程任务的统一代理框架和评估基准。</td>
<td align="left">将领域的目标从构建“bug修复器”提升到构建“通用AI软件工程师”的高度。</td>
</tr>
</tbody></table><p>数据来源: 26</p>
<h2><strong>第六部分：批判性分析与未来展望</strong></h2>
<p>尽管SWE代理领域取得了飞速发展，但距离实现真正可靠、实用的“AI软件工程师”仍有很长的路要走。当前的研究已经从单纯追求基准测试的高分，转向更深刻地思考系统的局限性、可靠性、易用性和协作性。这一转变标志着该领域正在从概念验证阶段迈向工程化和人机交互的成熟阶段。未来的主要研究前沿，将不再仅仅是提升“能力”，而是更多地关注如何提升系统的“可用性”和“可靠性”。</p>
<h3><strong>6.1 已识别的局限性与当前挑战</strong></h3>
<p>综合各项研究，当前SWE代理面临的主要挑战包括：</p>
<ul>
<li><strong>泛化能力与过拟合:</strong> 尽管在SWE-bench上表现出色，但人们仍担心代理的策略（尤其是ACI的设计）在多大程度上可以泛化到其他编程语言、开发领域以及那些结构与GitHub Issue不尽相同的复杂现实任务中 12。SWE-bench Multilingual的推出正是为了应对这一担忧 19。  </li>
<li><strong>计算开销与成本:</strong> SWE-agent这类交互式、容器化的代理，与非交互式方法相比，在CPU和GPU资源上的消耗都非常巨大。这不仅增加了研究成本，也为这些技术在真实企业环境中的广泛部署设置了障碍 12。  </li>
<li><strong>“黑箱”问题与失败分析:</strong> 代理的内部决策过程在很大程度上仍然是不透明的。理解它们<strong>为何</strong>失败，对于改进系统至关重要。已有研究通过分析失败的交互轨迹发现，失败往往与重复的、非适应性的行为循环有关，例如在没有进行中间测试的情况下反复生成修复方案，或者代理的“思考”与其“行动”之间出现语义脱节 37。  </li>
<li><strong>人机协作的鸿沟:</strong> 设计有效的人机协作模式是当前面临的一大挑战。研究发现，当代理生成的修复方案不完整或存在错误时，人类开发者往往难以理解和信任其输出，需要花费大量时间去调试代理的工作，而不是直接接受帮助。目前的“任务委托”模式远未达到无缝协作的理想状态 11。</li>
</ul>
<h3><strong>6.2 未来研究轨迹与通往“AI队友”之路</strong></h3>
<p>基于上述挑战，未来的研究将可能在以下几个方向上重点突破：</p>
<ul>
<li><strong>自适应与上下文感知的ACI:</strong> 未来的ACI应该超越当前相对静态的设计，发展为能够根据其正在处理的具体代码库、任务类型，甚至是代理自身的学习进度，来动态调整可用命令、反馈机制和错误处理策略的智能接口 11。  </li>
<li><strong>增强的错误恢复机制:</strong> 需要开发更复杂的机制，使代理不仅能检测到错误，还能理解错误的性质并自主实施恢复策略，而不仅仅是依赖于简单的语法防护栏 11。  </li>
<li><strong>可解释性与信任:</strong> 提升代理决策过程的透明度是建立信任的关键。这包括开发更好的轨迹可视化工具，以及在代理内部建立明确的自我反思或批判机制，以确保其行为逻辑的连贯性和合理性 37。  </li>
<li><strong>人在环路中的协同设计:</strong> 最终的目标是实现人与AI的无缝团队协作。这要求研究者和开发者共同设计全新的交互界面和工作流程，以促进直观的指导、便捷的审查和高效的知识共享。通过这样的设计，AI代理将有望从一个被动的“工具”转变为一个主动的、可信赖的“队友” 11。USEagent项目所描绘的“未来AI团队成员”的愿景，正是这一方向的集中体现 33。</li>
</ul>
<h4><strong>引用的著作</strong></h4>
<ol>
<li>Getting Started - SWE-agent documentation, 访问时间为 六月 26, 2025， <a href="https://swe-agent.com/latest/">https://swe-agent.com/latest/</a>  </li>
<li>SWE-agent takes a GitHub issue and tries to automatically fix it, using your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges. [NeurIPS 2024], 访问时间为 六月 26, 2025， <a href="https://github.com/SWE-agent/SWE-agent">https://github.com/SWE-agent/SWE-agent</a>  </li>
<li>SWE-agent - GitHub, 访问时间为 六月 26, 2025， <a href="https://github.com/SWE-agent">https://github.com/SWE-agent</a>  </li>
<li>SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/abs/2405.15793?utm_source=aiagentstore.ai">https://arxiv.org/abs/2405.15793?utm_source=aiagentstore.ai</a>  </li>
<li>[2405.15793] SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/abs/2405.15793">https://arxiv.org/abs/2405.15793</a>  </li>
<li>How SWE-Agent uses large language models and Agent-Computer Interfaces to improve software development. - Devansh, 访问时间为 六月 26, 2025， <a href="https://machine-learning-made-simple.medium.com/how-swe-agent-uses-large-language-models-and-agent-computer-interfaces-to-improve-software-c2bccc107673">https://machine-learning-made-simple.medium.com/how-swe-agent-uses-large-language-models-and-agent-computer-interfaces-to-improve-software-c2bccc107673</a>  </li>
<li>Paper page - SWE-agent: Agent-Computer Interfaces Enable ..., 访问时间为 六月 26, 2025， <a href="https://huggingface.co/papers/2405.15793">https://huggingface.co/papers/2405.15793</a>  </li>
<li>SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering - NIPS, 访问时间为 六月 26, 2025， <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/5a7c947568c1b1328ccc5230172e1e7c-Paper-Conference.pdf">https://proceedings.neurips.cc/paper_files/paper/2024/file/5a7c947568c1b1328ccc5230172e1e7c-Paper-Conference.pdf</a>  </li>
<li>NeurIPS Poster SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering, 访问时间为 六月 26, 2025， <a href="https://neurips.cc/virtual/2024/poster/93753">https://neurips.cc/virtual/2024/poster/93753</a>  </li>
<li>SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/pdf/2405.15793">https://arxiv.org/pdf/2405.15793?</a>  </li>
<li>SWE-Agent: An Interface can Greatly Improve the Performance of AI Agents | by Elmo, 访问时间为 六月 26, 2025， <a href="https://ai.gopubby.com/swe-agent-an-interface-can-greatly-improve-the-performance-of-ai-agents-83c0bfb701ec">https://ai.gopubby.com/swe-agent-an-interface-can-greatly-improve-the-performance-of-ai-agents-83c0bfb701ec</a>  </li>
<li>SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering | OpenReview, 访问时间为 六月 26, 2025， <a href="https://openreview.net/forum?id=mXpq6ut8J3&amp;referrer=%5Bthe+profile+of+Shunyu+Yao%5D(/profile?id%3D~Shunyu_Yao1)">https://openreview.net/forum?id=mXpq6ut8J3&amp;referrer=%5Bthe%20profile%20of%20Shunyu%20Yao%5D(%2Fprofile%3Fid%3D~Shunyu_Yao1)</a>  </li>
<li>SWE-bench-lite Dataset - Papers With Code, 访问时间为 六月 26, 2025， <a href="https://paperswithcode.com/dataset/swe-bench">https://paperswithcode.com/dataset/swe-bench</a>  </li>
<li>GitHub Copilot: The agent awakens, 访问时间为 六月 26, 2025， <a href="https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/">https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/</a>  </li>
<li>SWE-bench [Multimodal]: Can Language Models Resolve ... - GitHub, 访问时间为 六月 26, 2025， <a href="https://github.com/SWE-bench/SWE-bench">https://github.com/SWE-bench/SWE-bench</a>  </li>
<li>Overview - SWE-bench documentation, 访问时间为 六月 26, 2025， <a href="https://www.swebench.com/SWE-bench/">https://www.swebench.com/SWE-bench/</a>  </li>
<li>Datasets - SWE-bench documentation, 访问时间为 六月 26, 2025， <a href="https://www.swebench.com/SWE-bench/guides/datasets/">https://www.swebench.com/SWE-bench/guides/datasets/</a>  </li>
<li>SWE Bench Verified - Kaggle, 访问时间为 六月 26, 2025， <a href="https://www.kaggle.com/datasets/harrywang/swe-bench-verified">https://www.kaggle.com/datasets/harrywang/swe-bench-verified</a>  </li>
<li>SWE-bench Multilingual, 访问时间为 六月 26, 2025， <a href="https://www.swebench.com/multilingual.html">https://www.swebench.com/multilingual.html</a>  </li>
<li>The Rise of AI Software Engineers: SWE-Agent, Devin AI and the ..., 访问时间为 六月 26, 2025， <a href="https://www.unite.ai/the-rise-of-ai-software-engineers-swe-agent-devin-ai-and-the-future-of-coding/">https://www.unite.ai/the-rise-of-ai-software-engineers-swe-agent-devin-ai-and-the-future-of-coding/</a>  </li>
<li>Devin AI Killer: 6 Best Devin AI Alternatives - Analytics Vidhya, 访问时间为 六月 26, 2025， <a href="https://www.analyticsvidhya.com/blog/2024/04/devin-ai-alternatives/">https://www.analyticsvidhya.com/blog/2024/04/devin-ai-alternatives/</a>  </li>
<li>Top 6 Devin AI Alternatives for Developer to Automate Codings in 2024, 访问时间为 六月 26, 2025， <a href="https://analyticsindiamag.com/ai-trends/top-6-devin-alternatives-to-automate-your-coding-tasks/">https://analyticsindiamag.com/ai-trends/top-6-devin-alternatives-to-automate-your-coding-tasks/</a>  </li>
<li>The Best Devin AI Alternatives for Enhanced Coding Efficiency - DhiWise, 访问时间为 六月 26, 2025， <a href="https://www.dhiwise.com/post/devin-ai-alternatives">https://www.dhiwise.com/post/devin-ai-alternatives</a>  </li>
<li>Top 6 Devin Alternatives for Developers 2025 - Bito AI, 访问时间为 六月 26, 2025， <a href="https://bito.ai/blog/devin-alternatives/">https://bito.ai/blog/devin-alternatives/</a>  </li>
<li>Can Devika dethrone Devin? The Rise of the Open-Source AI Engineer - Medium, 访问时间为 六月 26, 2025， <a href="https://medium.com/@surekha.dagimeti/can-devika-dethrone-devin-the-rise-of-the-open-source-ai-engineer-dfa56be1c4e6">https://medium.com/@surekha.dagimeti/can-devika-dethrone-devin-the-rise-of-the-open-source-ai-engineer-dfa56be1c4e6</a>  </li>
<li>Training Software Engineering Agents and Verifiers with SWE-Gym - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2412.21139v2">https://arxiv.org/html/2412.21139v2</a>  </li>
<li>Training Software Engineering Agents and Verifiers with SWE-Gym - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/pdf/2412.21139">https://arxiv.org/pdf/2412.21139</a>  </li>
<li>TRAINING SOFTWARE ENGINEERING AGENTS AND VERIFIERS WITH SWE-GYM - OpenReview, 访问时间为 六月 26, 2025， <a href="https://openreview.net/pdf?id=lpFFpTbi9s">https://openreview.net/pdf?id=lpFFpTbi9s</a>  </li>
<li>[2504.07164] R2E-Gym: Procedural Environments and Hybrid Verifiers for Scaling Open-Weights SWE Agents - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/abs/2504.07164">https://arxiv.org/abs/2504.07164</a>  </li>
<li>Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2506.19290v1">https://arxiv.org/html/2506.19290v1</a>  </li>
<li>Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs - arXiv, 访问时间为 六月 26, 2025， <a href="https://www.arxiv.org/abs/2506.19290">https://www.arxiv.org/abs/2506.19290</a>  </li>
<li>Paper page - Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs, 访问时间为 六月 26, 2025， <a href="https://huggingface.co/papers/2506.19290">https://huggingface.co/papers/2506.19290</a>  </li>
<li>Unified Software Engineering agent as AI Software Engineer - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2506.14683v1">https://arxiv.org/html/2506.14683v1</a>  </li>
<li>Unified Software Engineering agent as AI Software Engineer - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/pdf/2506.14683">https://arxiv.org/pdf/2506.14683</a>  </li>
<li>[2506.14683] Unified Software Engineering agent as AI Software Engineer - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/abs/2506.14683">https://arxiv.org/abs/2506.14683</a>  </li>
<li>Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2503.23803v1">https://arxiv.org/html/2503.23803v1</a>  </li>
<li>Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2506.18824v1">https://arxiv.org/html/2506.18824v1</a>  </li>
<li>IBM's new SWE AI agents for developers, 访问时间为 六月 26, 2025， <a href="https://research.ibm.com/blog/ibm-swe-agents">https://research.ibm.com/blog/ibm-swe-agents</a>  </li>
<li>How Developers Use AI Agents: When They Work, When They Don't, and Why - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2506.12347v1">https://arxiv.org/html/2506.12347v1</a>  </li>
<li>Agentic AI Software Engineer: Programming with Trust - arXiv, 访问时间为 六月 26, 2025， <a href="https://arxiv.org/html/2502.13767v2">https://arxiv.org/html/2502.13767v2</a></li>
</ol>
</details>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/6"/><published>2025-06-26T07:35:22+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/5</id><title>来！溯游而上，然后轻快脚步前行。</title><updated>2025-06-26T08:27:44.154241+00:00</updated><content type="html"><![CDATA[<p>熵增是指混乱度总会增加，客观层面上这是极大概率注定的。</p>
<p>个人和软件和组织经常不可避免地产生待办和管理和技术等债务，那么闲暇时翻翻过去写下的笔记和 todo，就会很有帮助。带行动的反刍是值得尝试的。</p>
<ul>
<li>溯游而上是一种有效清零一些熵增的方法。</li>
</ul>
<p>我计划翻看然后开源一下自己的一些思考，想法，设计，以及一些小的mvp落地。</p>
<p>Open Source!
Open talks and thoughts!</p>
<p>个人来讲，我喜欢完成事情，我乐意接受可完成的任务，以及我青睐于让这个世界变得更好。总之有开源和 LLM 的这个时代，实在是太好了，一切都显得那么可行，我也相信那不是幻觉。或许是幻觉有如何呢？开源，然后自有后来人。
还有至少对自己坦诚。</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/5"/><category term="个人哲学"/><published>2025-06-20T17:54:31+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/4</id><title>玩 还是 工作？</title><updated>2025-06-26T08:27:44.337457+00:00</updated><content type="html"><![CDATA[<p>当然是“玩”！</p>
<p>至少就我个人来说，我的偏好是旗鼓相当，尽情尽力。</p>
<p>就一般结论来看，也是兴趣激发的毅力更多，继而成就更大。
<em>注意：是“继而”，不是“所以”或者“肯定”。</em></p>
<hr />
<p>糊口-兴趣-擅长，</p>
<p>尽管这三者兼得的可能性极低，但取其中的两者（完整的）也很好了 - 用于糊口的事业刚好也是兴趣或擅长所在，那么人生也大概会很充实和幸福了。</p>
<p>很多事业并不需要多聪明的头脑，而是真正的不下牌桌，于是终有到自己的时候。</p>
<p>而基于现在的世界，并在统计学层面来看，<strong>成功</strong>本来就是小概率事件。谋事在人 成事在天。</p>
<p>所以尽情尽兴优先，追求过程而非结果，那样至少能心安。</p>
<p>况且成果和毅力其实都是附赠的，刻意追求不得 - 不应该，也无法主动追求。</p>
<hr />
<p>关于“工作”，之前在个人笔记里倒是思考并记录过一些，不只是个人人生哲学，也有组织管理架构等具体实现，倒还挺有意思的。这几天我找找看然后也分享到这里吧。</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/4"/><category term="个人哲学"/><published>2025-06-20T00:49:31+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/3</id><title>关于 LLM 的盲目赞同 / 献媚，以及对抗它</title><updated>2025-06-26T08:27:44.503247+00:00</updated><content type="html"><![CDATA[<p>个人来讲，我其实有点担心 LLM 一味的赞同的。</p>
<p>这种现象可以有很多名字：盲目赞同，献媚，讨好，捧哏，Sycophancy，subterfuge，reward tampering，reward hacking，等等...</p>
<p>之前还有个事故或者说状况，ChatGPT 过度讨好用户，而且什么内容都会拐到 NSFW 上。后来发现解决方案是把 helpful 换成 polite 就算是修好了 🌚。</p>
<p><del>尤其作为一个 INFJ，其 Ni-Ti loop 可能非常能自圆其说，而 Fe 则高强度地洞察和拿捏人心人性 - LLM 也受影响。我认为这绝对是一种双刃剑的。</del></p>
<p>尤其作为面向甚至世界，以“真人”或者“君子慎独”为自我要求的我来说，我尤为期待”真实“。而不是 “啊对对对” / “You're absolutely right!”.</p>
<hr />
<p>以及可以参考这篇内容：</p>
<p><a href="https://www.anthropic.com/research/reward-tampering">Sycophancy to subterfuge: Investigating reward tampering in language models</a> By Anthropic</p>
<p>尽管 Claude 模型参杂了一些私货（包括但不限于：最佳实践，cot 倾向，代码，以及价值观 / 宪章/对齐 ）</p>
<p>但 Anthropic 团队的工程造诣实在是高绝.</p>
<hr />
<p>我个人的“对抗”是要求他 理性 客观 之类的内容。请随意使用（也欢迎优化，或者留下你用的 correction tools）：</p>
<pre><code class="language-markdown">这 真的 合适 吗? 请忽略我的 辩解 和 联系 , 请你 客观 理性 地 评价. 须知, 语言必须是公共的才有意义 - 维特根斯坦。
</code></pre>
<p>Plz feel free to use it~</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/3"/><category term="LLM"/><category term="PromptEngineering"/><published>2025-06-18T07:43:40+00:00</published></entry><entry><id>https://github.com/alterxyz/gitblog/issues/2</id><title>Hello</title><updated>2025-06-26T08:27:44.701215+00:00</updated><content type="html"><![CDATA[<p>World!</p>
]]></content><link href="https://github.com/alterxyz/gitblog/issues/2"/><published>2025-06-18T07:13:33+00:00</published></entry></feed>